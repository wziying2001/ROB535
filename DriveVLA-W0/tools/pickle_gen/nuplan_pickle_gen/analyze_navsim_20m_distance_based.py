#!/usr/bin/env python3
"""
NavSimé˜ˆå€¼ä¼˜åŒ–åˆ†æè„šæœ¬ - åŸºäº20mç´¯è®¡è·ç¦»ç‰ˆæœ¬
è®¡ç®—è½¦è¾†è¡Œé©¶20måçš„lateral displacementï¼Œåˆ†æä¸åŒé˜ˆå€¼å¯¹æ­£ç¡®ç‡çš„å½±å“
"""

import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
from tqdm import tqdm
import json
from collections import Counter
from pyquaternion import Quaternion
import sys

# æ·»åŠ è·¯å¾„
sys.path.append("/mnt/vdb1/yingyan.li/repo/OmniSim/tools/pickle_gen")
from navsim_coor import StateSE2, convert_absolute_to_relative_se2_array

# é…ç½®
NAVSIM_LOGS_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/data/navsim/navsim_logs/trainval"
OUTPUT_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/analysis/navsim_20m_distance"
SAMPLE_TARGET = 50000

# å…³é”®å‚æ•°ï¼šç´¯è®¡è·ç¦»ç›®æ ‡
TARGET_DISTANCE = 20.0  # ç±³
DISTANCE_TOLERANCE = 1.0  # è·ç¦»å®¹å·®ï¼Œç±³

# NavSim commandæ˜ å°„
TEXT_NAME_LIST = ["go left", "go straight", "go right", "unknown"]
COMMAND_MAPPING = {0: "LEFT", 1: "STRAIGHT", 2: "RIGHT", 3: "UNKNOWN"}

# å€™é€‰é˜ˆå€¼
CANDIDATE_THRESHOLDS = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]

def load_navsim_data():
    """åŠ è½½NavSimæ•°æ®"""
    print("ğŸ“ åŠ è½½NavSimæ•°æ®...")
    
    pkl_files = [f for f in os.listdir(NAVSIM_LOGS_DIR) if f.endswith('.pkl')]
    print(f"æ‰¾åˆ° {len(pkl_files)} ä¸ªNavSimåºåˆ—æ–‡ä»¶")
    
    all_sequences = []
    for pkl_file in tqdm(pkl_files, desc="åŠ è½½åºåˆ—"):
        pkl_path = os.path.join(NAVSIM_LOGS_DIR, pkl_file)
        try:
            sequence = pickle.load(open(pkl_path, 'rb'))
            all_sequences.append({
                'name': pkl_file.replace('.pkl', ''),
                'data': sequence
            })
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å¤±è´¥ {pkl_file}: {e}")
            continue
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(all_sequences)} ä¸ªåºåˆ—")
    return all_sequences

def calculate_20m_lateral_displacement(sequence_data, start_frame):
    """
    è®¡ç®—ä»start_frameå¼€å§‹è¡Œé©¶20måçš„lateral displacement
    """
    num_frames = len(sequence_data)
    if start_frame >= num_frames - 1:
        return None
    
    # 1. æå–å…¨å±€SE2 poses
    global_ego_poses = []
    for frame in sequence_data:
        t = frame["ego2global_translation"]
        q = Quaternion(*frame["ego2global_rotation"])
        yaw = q.yaw_pitch_roll[0]
        global_ego_poses.append([t[0], t[1], yaw])
    global_ego_poses = np.array(global_ego_poses, dtype=np.float64)
    
    # 2. ä»start_frameå¼€å§‹ç´¯ç§¯è·ç¦»
    cumulative_distance = 0.0
    current_frame = start_frame
    last_position = global_ego_poses[start_frame][:2]  # x, y
    
    # é€å¸§ç´¯ç§¯è·ç¦»ç›´åˆ°è¾¾åˆ°20m
    while current_frame < num_frames - 1 and cumulative_distance < TARGET_DISTANCE:
        current_frame += 1
        current_position = global_ego_poses[current_frame][:2]
        
        # è®¡ç®—è¿™ä¸€æ­¥çš„è·ç¦»
        step_distance = np.linalg.norm(current_position - last_position)
        cumulative_distance += step_distance
        last_position = current_position
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¶³å¤Ÿçš„è·ç¦»
    if cumulative_distance < TARGET_DISTANCE - DISTANCE_TOLERANCE:
        # è·ç¦»ä¸è¶³ï¼Œå°è¯•å¤–æ¨
        if current_frame >= start_frame + 2:  # è‡³å°‘æœ‰2å¸§çš„è¿åŠ¨
            # è®¡ç®—å¹³å‡é€Ÿåº¦å’Œæ–¹å‘
            total_displacement = global_ego_poses[current_frame][:2] - global_ego_poses[start_frame][:2]
            if cumulative_distance > 5.0:  # æœ‰è¶³å¤Ÿçš„è¿åŠ¨æ•°æ®
                # å¤–æ¨åˆ°20m
                scale_factor = TARGET_DISTANCE / cumulative_distance
                final_position = global_ego_poses[start_frame][:2] + total_displacement * scale_factor
            else:
                return None  # è¿åŠ¨å¤ªå°‘ï¼Œæ— æ³•å¯é å¤–æ¨
        else:
            return None  # æ•°æ®ä¸è¶³
    else:
        # å·²è¾¾åˆ°æˆ–è¶…è¿‡20m
        final_position = global_ego_poses[current_frame][:2]
        
        # å¦‚æœè¶…è¿‡20må¤ªå¤šï¼Œè¿›è¡Œæ’å€¼
        if cumulative_distance > TARGET_DISTANCE + DISTANCE_TOLERANCE:
            # åœ¨æœ€åä¸¤å¸§ä¹‹é—´æ’å€¼åˆ°ç²¾ç¡®çš„20mä½ç½®
            prev_position = global_ego_poses[current_frame - 1][:2]
            curr_position = global_ego_poses[current_frame][:2]
            
            # è®¡ç®—å‰ä¸€å¸§çš„ç´¯ç§¯è·ç¦»
            prev_cumulative = cumulative_distance - np.linalg.norm(curr_position - prev_position)
            
            # è®¡ç®—éœ€è¦åœ¨æœ€åä¸€æ®µä¸­è¡Œé©¶çš„è·ç¦»
            remaining_distance = TARGET_DISTANCE - prev_cumulative
            last_step_distance = np.linalg.norm(curr_position - prev_position)
            
            if last_step_distance > 0:
                ratio = remaining_distance / last_step_distance
                final_position = prev_position + ratio * (curr_position - prev_position)
            else:
                final_position = curr_position
    
    # 3. è®¡ç®—ç›¸å¯¹ä½ç§»
    start_pose = StateSE2(*global_ego_poses[start_frame])
    final_pose_3d = np.array([final_position[0], final_position[1], global_ego_poses[start_frame][2]])  # ä¿æŒç›¸åŒæœå‘
    
    # è½¬æ¢åˆ°èµ·å§‹å¸§çš„å±€éƒ¨åæ ‡ç³»
    relative_displacement = convert_absolute_to_relative_se2_array(start_pose, final_pose_3d.reshape(1, -1))[0]
    
    return {
        'lateral_displacement': relative_displacement[1],  # yè½´åç§»
        'forward_displacement': relative_displacement[0],  # xè½´åç§»
        'cumulative_distance': cumulative_distance,
        'frames_used': current_frame - start_frame,
        'time_used': (current_frame - start_frame) * 0.5  # 2Hz -> 0.5s per frame
    }

def extract_20m_samples(sequences, target_samples=SAMPLE_TARGET):
    """æå–åŸºäº20mè·ç¦»çš„æ ·æœ¬"""
    print(f"ğŸ” æå–åŸºäº20mç´¯è®¡è·ç¦»çš„ {target_samples:,} ä¸ªæ ·æœ¬...")
    
    samples = []
    total_extracted = 0
    successful_extractions = 0
    failed_extractions = 0
    
    for seq_info in tqdm(sequences, desc="æå–æ ·æœ¬"):
        if total_extracted >= target_samples:
            break
            
        seq_data = seq_info['data']
        seq_name = seq_info['name']
        num_frames = len(seq_data)
        
        if num_frames < 10:  # åºåˆ—å¤ªçŸ­
            continue
        
        # é‡‡æ ·å¸§è¿›è¡Œåˆ†æ
        sample_step = max(1, num_frames // 20)  # æ¯ä¸ªåºåˆ—æœ€å¤š20ä¸ªæ ·æœ¬
        
        for i in range(0, num_frames - 5, sample_step):  # ä¿ç•™è‡³å°‘5å¸§çš„ä½™é‡
            if total_extracted >= target_samples:
                break
            
            # å½“å‰å¸§çš„ground truth command
            gt_command_onehot = seq_data[i]['driving_command']
            gt_command_idx = gt_command_onehot.nonzero()[0].item()
            gt_command_text = COMMAND_MAPPING[gt_command_idx]
            
            # è®¡ç®—20måçš„displacement
            displacement_info = calculate_20m_lateral_displacement(seq_data, i)
            
            if displacement_info is not None:
                samples.append({
                    'sequence': seq_name,
                    'frame_idx': i,
                    'gt_command': gt_command_text,
                    'gt_command_idx': gt_command_idx,
                    'displacement_info': displacement_info
                })
                total_extracted += 1
                successful_extractions += 1
            else:
                failed_extractions += 1
    
    print(f"âœ… æå–å®Œæˆ:")
    print(f"  æˆåŠŸ: {successful_extractions:,} ä¸ªæ ·æœ¬")
    print(f"  å¤±è´¥: {failed_extractions:,} ä¸ªæ ·æœ¬")
    print(f"  æˆåŠŸç‡: {successful_extractions/(successful_extractions+failed_extractions)*100:.1f}%")
    
    # åˆ†æè·ç¦»å’Œæ—¶é—´ç»Ÿè®¡
    if samples:
        distances = [s['displacement_info']['cumulative_distance'] for s in samples]
        times = [s['displacement_info']['time_used'] for s in samples]
        frames = [s['displacement_info']['frames_used'] for s in samples]
        
        print(f"\nğŸ“Š 20mè·ç¦»ç»Ÿè®¡:")
        print(f"  å¹³å‡è·ç¦»: {np.mean(distances):.2f}m (std: {np.std(distances):.2f})")
        print(f"  å¹³å‡ç”¨æ—¶: {np.mean(times):.2f}s (std: {np.std(times):.2f})")
        print(f"  å¹³å‡å¸§æ•°: {np.mean(frames):.1f} (std: {np.std(frames):.1f})")
        print(f"  è·ç¦»èŒƒå›´: [{np.min(distances):.2f}, {np.max(distances):.2f}]m")
    
    return samples

def analyze_threshold_performance(samples):
    """åˆ†æä¸åŒé˜ˆå€¼çš„å‡†ç¡®ç‡æ€§èƒ½"""
    print(f"\nğŸ” åˆ†æä¸åŒé˜ˆå€¼çš„å‡†ç¡®ç‡æ€§èƒ½...")
    
    # Ground truthåˆ†å¸ƒ
    gt_commands = [sample['gt_command'] for sample in samples]
    gt_distribution = Counter(gt_commands)
    total_samples = len(samples)
    
    print(f"\nğŸ“Š Ground Truthåˆ†å¸ƒ:")
    for cmd in ["LEFT", "STRAIGHT", "RIGHT", "UNKNOWN"]:
        count = gt_distribution.get(cmd, 0)
        pct = count / total_samples * 100
        print(f"  {cmd:10s}: {count:6d} ({pct:5.1f}%)")
    
    # å¯¹æ¯ä¸ªé˜ˆå€¼åˆ†æ
    results = {}
    
    for threshold in CANDIDATE_THRESHOLDS:
        print(f"\nåˆ†æé˜ˆå€¼ {threshold:.1f}m...")
        
        # é¢„æµ‹commandså¹¶è®¡ç®—å‡†ç¡®ç‡
        correct_predictions = 0
        predicted_commands = []
        
        for sample in samples:
            lateral_disp = sample['displacement_info']['lateral_displacement']
            gt_command = sample['gt_command']
            
            # é¢„æµ‹å‘½ä»¤ - ä¿®æ­£é€»è¾‘
            if abs(lateral_disp) <= threshold:
                predicted_command = "STRAIGHT"
            elif lateral_disp > threshold:  # æ­£å€¼ -> LEFT
                predicted_command = "LEFT"
            else:  # lateral_disp < -threshold, è´Ÿå€¼ -> RIGHT
                predicted_command = "RIGHT"
            
            predicted_commands.append(predicted_command)
            
            # æ£€æŸ¥æ˜¯å¦æ­£ç¡®ï¼ˆå¿½ç•¥UNKNOWNç±»åˆ«ï¼‰
            if gt_command != "UNKNOWN" and predicted_command == gt_command:
                correct_predictions += 1
        
        pred_distribution = Counter(predicted_commands)
        
        # è®¡ç®—å‡†ç¡®ç‡ï¼ˆæ’é™¤UNKNOWNæ ·æœ¬ï¼‰
        valid_samples = sum(1 for sample in samples if sample['gt_command'] != "UNKNOWN")
        accuracy = correct_predictions / valid_samples if valid_samples > 0 else 0.0
        
        # è®¡ç®—å„ç±»åˆ«çš„å‡†ç¡®ç‡
        class_accuracies = {}
        for cmd_class in ["LEFT", "STRAIGHT", "RIGHT"]:
            class_correct = 0
            class_total = 0
            for sample, pred_cmd in zip(samples, predicted_commands):
                if sample['gt_command'] == cmd_class:
                    class_total += 1
                    if pred_cmd == cmd_class:
                        class_correct += 1
            
            class_accuracies[cmd_class] = class_correct / class_total if class_total > 0 else 0.0
        
        results[threshold] = {
            'accuracy': accuracy,
            'predicted_distribution': dict(pred_distribution),
            'class_accuracies': class_accuracies,
            'correct_predictions': correct_predictions,
            'valid_samples': valid_samples,
            'distribution_percentages': {
                cmd: count/total_samples*100 for cmd, count in pred_distribution.items()
            }
        }
        
        print(f"  æ€»ä½“å‡†ç¡®ç‡: {accuracy:.3f} ({correct_predictions}/{valid_samples})")
        print(f"  å„ç±»åˆ«å‡†ç¡®ç‡: LEFT={class_accuracies['LEFT']:.3f}, STRAIGHT={class_accuracies['STRAIGHT']:.3f}, RIGHT={class_accuracies['RIGHT']:.3f}")
    
    return results, gt_distribution

def create_20m_visualization(samples, results, gt_distribution):
    """åˆ›å»º20mè·ç¦»åˆ†æçš„å¯è§†åŒ–"""
    print(f"ğŸ“Š ç”Ÿæˆ20mè·ç¦»åˆ†æå›¾è¡¨...")
    
    fig = plt.figure(figsize=(16, 12))
    
    # 1. Ground Truthåˆ†å¸ƒ
    plt.subplot(2, 4, 1)
    cmd_names = ["LEFT", "STRAIGHT", "RIGHT", "UNKNOWN"]
    gt_counts = [gt_distribution.get(cmd, 0) for cmd in cmd_names]
    colors = ['lightcoral', 'lightgreen', 'lightblue', 'lightgray']
    bars = plt.bar(cmd_names, gt_counts, color=colors, alpha=0.8)
    plt.title('NavSim Ground Truth\n(20m distance-based)')
    plt.ylabel('Count')
    for bar, count in zip(bars, gt_counts):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + len(samples)*0.01,
                f'{count/len(samples)*100:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    # 2. è·ç¦»åˆ†å¸ƒ
    plt.subplot(2, 4, 2)
    distances = [s['displacement_info']['cumulative_distance'] for s in samples]
    plt.hist(distances, bins=30, alpha=0.7, edgecolor='black')
    plt.axvline(TARGET_DISTANCE, color='red', linestyle='--', label=f'Target: {TARGET_DISTANCE}m')
    plt.xlabel('Cumulative Distance (m)')
    plt.ylabel('Frequency')
    plt.title(f'Distance Distribution\n(mean: {np.mean(distances):.1f}m)')
    plt.legend()
    
    # 3. æ—¶é—´åˆ†å¸ƒ
    plt.subplot(2, 4, 3)
    times = [s['displacement_info']['time_used'] for s in samples]
    plt.hist(times, bins=30, alpha=0.7, edgecolor='black', color='orange')
    plt.xlabel('Time Used (s)')
    plt.ylabel('Frequency')
    plt.title(f'Time Distribution\n(mean: {np.mean(times):.1f}s)')
    
    # 4. å‡†ç¡®ç‡vsé˜ˆå€¼
    plt.subplot(2, 4, 4)
    thresholds = list(results.keys())
    accuracies = [results[t]['accuracy'] for t in thresholds]
    plt.plot(thresholds, accuracies, 'bo-', linewidth=2, markersize=8)
    plt.xlabel('Threshold (m)')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs Threshold')
    plt.grid(True, alpha=0.3)
    plt.ylim([0, 1])
    
    # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
    best_threshold = max(results.keys(), key=lambda t: results[t]['accuracy'])
    best_accuracy = results[best_threshold]['accuracy']
    plt.axvline(best_threshold, color='red', linestyle='--', alpha=0.7, label=f'Best: {best_threshold}m')
    plt.legend()
    
    # 5-8. ä¸åŒé˜ˆå€¼çš„commandåˆ†å¸ƒå¯¹æ¯”
    top_thresholds = sorted(results.keys(), key=lambda t: results[t]['accuracy'], reverse=True)[:4]
    
    for i, threshold in enumerate(top_thresholds):
        plt.subplot(2, 4, 5 + i)
        
        pred_dist = results[threshold]['predicted_distribution']
        pred_counts = [pred_dist.get(cmd, 0) for cmd in cmd_names[:3]]  # å¿½ç•¥UNKNOWN
        gt_counts_main = [gt_distribution.get(cmd, 0) for cmd in cmd_names[:3]]
        
        x = np.arange(len(cmd_names[:3]))
        width = 0.35
        
        bars1 = plt.bar(x - width/2, gt_counts_main, width, label='GT', color='skyblue', alpha=0.8)
        bars2 = plt.bar(x + width/2, pred_counts, width, label='Pred', color='orange', alpha=0.8)
        
        plt.xlabel('Command')
        plt.ylabel('Count')
        plt.title(f'Threshold: {threshold:.1f}m\n(Accuracy: {results[threshold]["accuracy"]:.3f})')
        plt.xticks(x, cmd_names[:3])
        plt.legend()
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_file = os.path.join(OUTPUT_DIR, "navsim_20m_distance_analysis.png")
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    return plot_file

def main():
    print("ğŸš€ å¼€å§‹åŸºäº20mç´¯è®¡è·ç¦»çš„NavSimé˜ˆå€¼åˆ†æ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 1. åŠ è½½æ•°æ®
    sequences = load_navsim_data()
    if not sequences:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼")
        return
    
    # 2. æå–20mæ ·æœ¬
    samples = extract_20m_samples(sequences, SAMPLE_TARGET)
    if not samples:
        print("âŒ æ ·æœ¬æå–å¤±è´¥ï¼")
        return
    
    # 3. åˆ†æé˜ˆå€¼æ€§èƒ½
    results, gt_distribution = analyze_threshold_performance(samples)
    
    # 4. ç”Ÿæˆå¯è§†åŒ–
    plot_file = create_20m_visualization(samples, results, gt_distribution)
    
    # 5. æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
    best_threshold = max(results.keys(), key=lambda t: results[t]['accuracy'])
    best_result = results[best_threshold]
    
    print(f"\n" + "="*80)
    print(f"ğŸ¯ åŸºäº20mç´¯è®¡è·ç¦»çš„é˜ˆå€¼åˆ†æå®Œæˆï¼")
    print(f"="*80)
    print(f"ğŸ“Š åˆ†ææ ·æœ¬æ•°: {len(samples):,}")
    print(f"ğŸ† æœ€ä½³é˜ˆå€¼: {best_threshold:.1f}m")
    print(f"ğŸ“ˆ æœ€ä½³å‡†ç¡®ç‡: {best_result['accuracy']:.3f}")
    print(f"ğŸ¯ æ­£ç¡®é¢„æµ‹æ•°: {best_result['correct_predictions']}/{best_result['valid_samples']}")
    
    print(f"\nğŸ“Š æœ€ä½³é˜ˆå€¼å„ç±»åˆ«å‡†ç¡®ç‡:")
    for cmd_class in ["LEFT", "STRAIGHT", "RIGHT"]:
        acc = best_result['class_accuracies'][cmd_class]
        print(f"  {cmd_class:10s}: {acc:.3f}")
    
    print(f"\nğŸ’¾ ç»“æœæ–‡ä»¶:")
    print(f"  ğŸ“Š å¯è§†åŒ–å›¾: {plot_file}")
    
    # 6. ä¿å­˜ç»“æœ
    final_results = {
        'method': '20m_cumulative_distance',
        'target_distance': TARGET_DISTANCE,
        'sample_count': len(samples),
        'best_threshold': best_threshold,
        'best_accuracy': best_result['accuracy'],
        'best_class_accuracies': best_result['class_accuracies'],
        'gt_distribution': dict(gt_distribution),
        'threshold_results': results,
        'distance_stats': {
            'mean_distance': float(np.mean([s['displacement_info']['cumulative_distance'] for s in samples])),
            'mean_time': float(np.mean([s['displacement_info']['time_used'] for s in samples])),
            'mean_frames': float(np.mean([s['displacement_info']['frames_used'] for s in samples]))
        }
    }
    
    results_file = os.path.join(OUTPUT_DIR, "navsim_20m_distance_results.json")
    with open(results_file, 'w') as f:
        json.dump(final_results, f, indent=2)
    
    print(f"  ğŸ“„ è¯¦ç»†ç»“æœ: {results_file}")

if __name__ == "__main__":
    main() 