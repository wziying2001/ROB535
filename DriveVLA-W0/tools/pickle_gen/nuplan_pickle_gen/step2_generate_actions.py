#!/usr/bin/env python3
"""
NuPlan Actionç”Ÿæˆè„šæœ¬ - Step 2
ä»posesç›´æ¥ç”Ÿæˆdelta actionsï¼Œç„¶åè®¡ç®—waypoints
poses (4x4) â†’ delta actions â†’ waypoints
ä¸¥æ ¼æŒ‰ç…§compareè„šæœ¬é€»è¾‘ï¼šå…ˆdeltaåwaypoints
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import glob
import pickle
import random
import sys
from pyquaternion import Quaternion

# æ·»åŠ å¿…è¦çš„è·¯å¾„
sys.path.append("/mnt/vdb1/yingyan.li/repo/OmniSim/tools/pickle_gen")
from navsim_coor import StateSE2, convert_absolute_to_relative_se2_array

# é…ç½®
SEGMENTS_JSON = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/intermediate/video_segments.json"
NUPLAN_JSON_DIR = "/mnt/vdb1/nuplan_json"
NAVSIM_LOGS_PATH = '/mnt/vdb1/yingyan.li/repo/OmniSim/data/navsim/navsim_logs/trainval'
OUTPUT_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/intermediate"
ANALYSIS_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/analysis"

# Actionå‚æ•°
SAMPLING_RATE = 10.0  # Hz
WAYPOINT_TIMES = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]  # æœªæ¥8ä¸ªæ—¶é—´ç‚¹
WAYPOINT_FRAMES = [int(t * SAMPLING_RATE) for t in WAYPOINT_TIMES]  # [5, 10, 15, ..., 40]

def load_segments():
    """åŠ è½½è§†é¢‘åˆ†å‰²ç»“æœ"""
    print("ğŸ“‹ åŠ è½½è§†é¢‘åˆ†å‰²ç»“æœ...")
    with open(SEGMENTS_JSON, 'r') as f:
        data = json.load(f)
    return data['segments'], data['metadata']

def poses_to_delta_actions(poses_from_current):
    """
    ç›´æ¥ä»posesè®¡ç®—delta actionsï¼ˆæŒ‰ç…§compareè„šæœ¬é€»è¾‘ï¼‰
    æ¯ä¸ªaction = ä»å½“å‰å¸§ç´¯ç§¯5ä¸ªè¿ç»­posesï¼ˆ0.5ç§’ï¼‰
    
    poses_from_current: ä»å½“å‰å¸§å¼€å§‹çš„ç›¸å¯¹å˜æ¢çŸ©é˜µåºåˆ— (remaining_frames, 4, 4)
    è¿”å›: 8ä¸ªdelta action [x, y, yaw] (8, 3)
    """
    actions = []
    
    for action_idx in range(8):  # 8ä¸ªactionï¼ˆæ¯ä¸ª0.5ç§’ï¼‰
        # æ¯ä¸ªactionç´¯ç§¯5ä¸ªè¿ç»­poses
        frame_start = action_idx * 5
        frame_end = frame_start + 5
        
        if frame_start < len(poses_from_current):
            # ç´¯ç§¯å˜æ¢
            cumulative_transform = np.eye(4, dtype=np.float64)
            for frame_idx in range(frame_start, min(frame_end, len(poses_from_current))):
                pose = poses_from_current[frame_idx].astype(np.float64)
                cumulative_transform = cumulative_transform @ pose
            
            # æå–ä½ç½®å’Œæœå‘å˜åŒ–
            dx = cumulative_transform[0, 3]
            dy = cumulative_transform[1, 3]
            dyaw = np.arctan2(cumulative_transform[1, 0], cumulative_transform[0, 0])
            
            actions.append([float(dx), float(dy), float(dyaw)])
        else:
            # è¶…å‡ºèŒƒå›´ï¼Œç”¨0å¡«å……
            actions.append([0.0, 0.0, 0.0])
    
    return np.array(actions, dtype=np.float64)

def delta_to_waypoints(delta_actions):
    """
    ä»delta actionsè®¡ç®—waypointsï¼ˆç´¯ç§¯ä½ç½®ï¼‰
    delta_actions: (8, 3) [dx, dy, dyaw]
    è¿”å›: (8, 3) waypoints [x, y, yaw]
    """
    waypoints = []
    current_pos = np.array([0.0, 0.0, 0.0], dtype=np.float64)
    
    for delta in delta_actions:
        current_pos = current_pos + delta
        # å½’ä¸€åŒ–è§’åº¦
        current_pos[2] = np.arctan2(np.sin(current_pos[2]), np.cos(current_pos[2]))
        waypoints.append(current_pos.copy())
    
    return np.array(waypoints, dtype=np.float64)

def extract_image_name(cam_path):
    """ä»ç›¸æœºè·¯å¾„ä¸­æå–å›¾ç‰‡æ–‡ä»¶å"""
    if isinstance(cam_path, str):
        return os.path.basename(cam_path)
    return None

def load_navsim_actions(log_name):
    """åŠ è½½NavSimçš„actionsï¼Œä»¥å›¾ç‰‡åç§°ä¸ºç´¢å¼•"""
    log_path = os.path.join(NAVSIM_LOGS_PATH, f"{log_name}.pkl")
    if not os.path.exists(log_path):
        return None
        
    with open(log_path, "rb") as f:
        scene = pickle.load(f)
    num_frames = len(scene)
    
    # 1. è¯»å‡ºæ‰€æœ‰å…¨å±€ SE2 pose
    global_ego_poses = []
    for fi in scene:
        t = fi["ego2global_translation"]
        q = Quaternion(*fi["ego2global_rotation"])
        yaw = q.yaw_pitch_roll[0]
        global_ego_poses.append([t[0], t[1], yaw])
    global_ego_poses = np.array(global_ego_poses, dtype=np.float64)
    
    # 2. æ‰¹é‡è®¡ç®— rel_all[i,j]
    rel_all = []
    for i in range(num_frames):
        origin = StateSE2(*global_ego_poses[i])
        rel = convert_absolute_to_relative_se2_array(origin, global_ego_poses)
        rel_all.append(rel)
    rel_all = np.stack(rel_all, axis=0)  # (N, N, 3)
    
    # 3. åˆ›å»ºä»¥å›¾ç‰‡åç§°ä¸ºé”®çš„å­—å…¸
    image_to_data = {}
    
    for i, fi in enumerate(scene):
        cam_path = fi.get('cams', {}).get('CAM_F0', {}).get('data_path', '')
        image_name = extract_image_name(cam_path)
        
        if image_name:
            # æ„é€ æœªæ¥8ä¸ªactionï¼ˆæ¯ä¸ª0.5ç§’ï¼‰
            action_list = []
            for j in range(8):
                if i + j < num_frames - 1:
                    # ä»ç¬¬i+jå¸§åˆ°ç¬¬i+j+1å¸§çš„ç›¸å¯¹å˜æ¢
                    dx, dy, dtheta = rel_all[i + j, i + j + 1]
                else:
                    dx = dy = dtheta = 0.0
                action_list.append([float(dx), float(dy), float(dtheta)])
            
            image_to_data[image_name] = {
                'frame_idx': i,
                'actions': np.array(action_list, dtype=np.float64),  # (8, 3)
                'token': fi.get("token", f"frame_{i}"),
                'timestamp': fi.get('timestamp', None)
            }
    
    return {'image_to_data': image_to_data, 'num_frames': num_frames}

def process_segment_actions(segment):
    """å¤„ç†å•ä¸ªsegmentçš„actions"""
    seq_name = segment['original_sequence']
    start_frame = segment['start_frame']
    frame_count = segment['frame_count']
    
    # åŠ è½½å¯¹åº”çš„JSON posesæ•°æ®
    json_path = os.path.join(NUPLAN_JSON_DIR, f"{seq_name}.json")
    try:
        with open(json_path, 'r') as f:
            json_data = json.load(f)
    except:
        return None, None
    
    poses = json_data.get('poses', [])
    if len(poses) < start_frame + 1:
        return None, None
    
    # è·å–segmentå¯¹åº”çš„posesï¼ˆä¸¥æ ¼æŒ‰ç…§JSONé¡ºåºï¼‰
    segment_poses = []
    for i in range(frame_count):
        frame_idx = start_frame + i
        if frame_idx < len(poses):
            segment_poses.append(np.array(poses[frame_idx], dtype=np.float64))
        else:
            # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œç”¨å•ä½çŸ©é˜µå¡«å……
            segment_poses.append(np.eye(4, dtype=np.float64))
    
    poses_array = np.array(segment_poses)  # (frame_count, 4, 4)
    
    actions = []
    waypoints_list = []
    
    # ä¸ºæ¯ä¸€å¸§ç”Ÿæˆaction
    for frame_idx in range(frame_count):
        # ç›´æ¥è®¡ç®—delta actions
        delta_actions = poses_to_delta_actions(poses_array[frame_idx:])
        actions.append(delta_actions)
        
        # ä»deltaè®¡ç®—waypoints
        waypoints = delta_to_waypoints(delta_actions)
        waypoints_list.append(waypoints)
    
    return np.array(actions, dtype=np.float64), waypoints_list

def compare_with_navsim(segment, actions, navsim_data):
    """ä¸NavSimæ•°æ®è¿›è¡Œæ¯”è¾ƒ"""
    if navsim_data is None:
        return None
    
    seq_name = segment['original_sequence']
    start_frame = segment['start_frame']
    frame_count = segment['frame_count']
    
    # åŠ è½½NuPlançš„å›¾ç‰‡ä¿¡æ¯
    json_path = os.path.join(NUPLAN_JSON_DIR, f"{seq_name}.json")
    try:
        with open(json_path, 'r') as f:
            json_data = json.load(f)
    except:
        return None
    
    images = json_data.get('images', [])
    if len(images) < start_frame + frame_count:
        return None
    
    # éšæœºé€‰æ‹©å‡ ä¸ªå¸§è¿›è¡Œæ¯”è¾ƒ
    num_samples = min(5, frame_count)
    sample_indices = random.sample(range(frame_count), num_samples)
    
    comparisons = []
    for local_idx in sample_indices:
        global_frame_idx = start_frame + local_idx
        if global_frame_idx < len(images):
            image_name = extract_image_name(images[global_frame_idx])
            
            if image_name and image_name in navsim_data['image_to_data']:
                nuplan_actions = actions[local_idx]  # (8, 3)
                navsim_actions = navsim_data['image_to_data'][image_name]['actions']  # (8, 3)
                
                # è®¡ç®—å·®å¼‚
                diff = nuplan_actions - navsim_actions
                max_diff = np.max(np.abs(diff))
                
                comparisons.append({
                    'image_name': image_name,
                    'local_frame_idx': local_idx,
                    'global_frame_idx': global_frame_idx,
                    'nuplan_actions': nuplan_actions,
                    'navsim_actions': navsim_actions,
                    'diff': diff,
                    'max_diff': max_diff,
                    'rmse': np.sqrt(np.mean(diff**2)),
                    'x_rmse': np.sqrt(np.mean(diff[:, 0]**2)),
                    'y_rmse': np.sqrt(np.mean(diff[:, 1]**2)),
                    'heading_rmse': np.sqrt(np.mean(diff[:, 2]**2))
                })
    
    return comparisons

def save_segment_actions(segment, actions, waypoints_list):
    """ä¿å­˜å•ä¸ªsegmentçš„actionså’Œwaypointsåˆ°ç‹¬ç«‹çš„.npyæ–‡ä»¶"""
    segment_id = segment['segment_id']
    actions_dir = os.path.join(OUTPUT_DIR, "actions")
    waypoints_dir = os.path.join(OUTPUT_DIR, "waypoints")
    os.makedirs(actions_dir, exist_ok=True)
    os.makedirs(waypoints_dir, exist_ok=True)
    
    # ä¿å­˜actions (deltaæ ¼å¼)
    actions_file = os.path.join(actions_dir, f"{segment_id}.npy")
    np.save(actions_file, actions)
    
    # ä¿å­˜waypoints (ç»å¯¹ä½ç½®)
    waypoints_array = np.array(waypoints_list, dtype=np.float64)  # (frame_count, 8, 3)
    waypoints_file = os.path.join(waypoints_dir, f"{segment_id}.npy")
    np.save(waypoints_file, waypoints_array)
    
    return actions_file, waypoints_file

def analyze_trajectory_distribution(all_actions):
    """åˆ†æè½¨è¿¹åˆ†å¸ƒ"""
    print("ğŸ“Š åˆ†æè½¨è¿¹åˆ†å¸ƒ...")
    
    # åˆ†æ0å¡«å……æƒ…å†µï¼ˆæ”¹è¿›ç‰ˆï¼‰
    # 1. å®Œå…¨0å¡«å……çš„trajectory
    completely_zero_mask = np.all(all_actions.reshape(len(all_actions), -1) == 0, axis=1)
    completely_zero_count = np.sum(completely_zero_mask)
    
    # 2. éƒ¨åˆ†0å¡«å……çš„actionä¸ªæ•°
    total_actions = all_actions.shape[0] * all_actions.shape[1]  # total_trajectories * 8
    zero_actions_mask = np.all(all_actions == 0, axis=2)  # (N, 8) - æ¯ä¸ªactionæ˜¯å¦ä¸º[0,0,0]
    zero_actions_count = np.sum(zero_actions_mask)
    
    # 3. æœ‰æ•ˆtrajectoryï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªéé›¶actionï¼‰
    non_zero_mask = np.any(all_actions.reshape(len(all_actions), -1) != 0, axis=1)
    valid_actions = all_actions[non_zero_mask]
    
    if len(valid_actions) == 0:
        print("âš ï¸ æ‰€æœ‰actionéƒ½æ˜¯0ï¼Œå¯èƒ½æ•°æ®æœ‰é—®é¢˜")
        valid_actions = all_actions
    
    # 4. åˆ†ææ¯ä¸ªtrajectoryçš„0å¡«å……æ¨¡å¼
    zero_padding_patterns = []
    for i, trajectory in enumerate(all_actions):
        zero_pattern = np.all(trajectory == 0, axis=1)  # (8,) å¸ƒå°”æ•°ç»„
        first_zero_idx = np.where(zero_pattern)[0]
        if len(first_zero_idx) > 0:
            first_zero_position = first_zero_idx[0]
            consecutive_zeros = np.sum(zero_pattern[first_zero_position:])
        else:
            first_zero_position = -1
            consecutive_zeros = 0
        
        zero_padding_patterns.append({
            'trajectory_idx': i,
            'total_zero_actions': np.sum(zero_pattern),
            'first_zero_position': int(first_zero_position) if first_zero_position >= 0 else -1,
            'consecutive_tail_zeros': int(consecutive_zeros),
            'has_zero_padding': consecutive_zeros > 0
        })
    
    # ç»Ÿè®¡0å¡«å……æ¨¡å¼
    trajectories_with_padding = sum(1 for p in zero_padding_patterns if p['has_zero_padding'])
    avg_consecutive_zeros = np.mean([p['consecutive_tail_zeros'] for p in zero_padding_patterns if p['has_zero_padding']]) if trajectories_with_padding > 0 else 0
    
    # 1. è½¨è¿¹æ€»é•¿åº¦åˆ†å¸ƒ
    trajectory_lengths = []
    for action in valid_actions:
        # è®¡ç®—8ä¸ªactionçš„ç´¯è®¡è·ç¦»
        distances = np.sqrt(action[:, 0]**2 + action[:, 1]**2)
        total_distance = np.sum(distances)
        trajectory_lengths.append(total_distance)
    
    # 2. è½¨è¿¹æœ€ç»ˆä½ç½®åˆ†å¸ƒ
    final_positions = []
    for action in valid_actions:
        cumulative_pos = np.cumsum(action, axis=0)  # ç´¯ç§¯ä½ç§»
        final_x, final_y = cumulative_pos[-1, 0], cumulative_pos[-1, 1]
        final_positions.append([final_x, final_y])
    
    # 3. è½¨è¿¹æ›²ç‡/å¼¯æ›²ç¨‹åº¦
    trajectory_curvatures = []
    for action in valid_actions:
        total_yaw_change = np.sum(np.abs(action[:, 2]))
        trajectory_curvatures.append(total_yaw_change)
    
    # 4. å„ä¸ªæ—¶é—´ç‚¹çš„åˆ†åˆ«ç»Ÿè®¡
    waypoint_stats = {}
    for i in range(8):
        waypoint_data = valid_actions[:, i, :]  # (N, 3)
        waypoint_stats[f'action_{i+1}'] = {
            'time': WAYPOINT_TIMES[i],
            'dx_mean': float(np.mean(waypoint_data[:, 0])),
            'dx_std': float(np.std(waypoint_data[:, 0])),
            'dy_mean': float(np.mean(waypoint_data[:, 1])),
            'dy_std': float(np.std(waypoint_data[:, 1])),
            'dyaw_mean': float(np.mean(waypoint_data[:, 2])),
            'dyaw_std': float(np.std(waypoint_data[:, 2])),
            'dx_range': [float(np.min(waypoint_data[:, 0])), float(np.max(waypoint_data[:, 0]))],
            'dy_range': [float(np.min(waypoint_data[:, 1])), float(np.max(waypoint_data[:, 1]))],
            'dyaw_range': [float(np.min(waypoint_data[:, 2])), float(np.max(waypoint_data[:, 2]))]
        }
    
    # 5. æ€»ä½“è½¨è¿¹ç»Ÿè®¡ï¼ˆæ›´æ–°ç‰ˆï¼‰
    trajectory_stats = {
        'total_trajectories': len(all_actions),
        'valid_trajectories': len(valid_actions),
        'completely_zero_trajectories': int(completely_zero_count),
        'trajectories_with_zero_padding': int(trajectories_with_padding),
        'total_actions': int(total_actions),
        'zero_filled_actions': int(zero_actions_count),
        'zero_padding_ratio': float(zero_actions_count) / float(total_actions),  # ä¿®æ­£ï¼šactionçº§åˆ«çš„0å¡«å……æ¯”ä¾‹
        'trajectory_zero_padding_ratio': float(trajectories_with_padding) / float(len(all_actions)),  # trajectoryçº§åˆ«çš„0å¡«å……æ¯”ä¾‹
        'avg_consecutive_zeros': float(avg_consecutive_zeros),
        'length_mean': float(np.mean(trajectory_lengths)),
        'length_std': float(np.std(trajectory_lengths)),
        'length_range': [float(np.min(trajectory_lengths)), float(np.max(trajectory_lengths))],
        'curvature_mean': float(np.mean(trajectory_curvatures)),
        'curvature_std': float(np.std(trajectory_curvatures)),
        'final_position_mean': [float(np.mean([pos[0] for pos in final_positions])), 
                               float(np.mean([pos[1] for pos in final_positions]))],
        'final_position_std': [float(np.std([pos[0] for pos in final_positions])), 
                              float(np.std([pos[1] for pos in final_positions]))]
    }
    
    return {
        'trajectory_stats': trajectory_stats,
        'waypoint_stats': waypoint_stats,
        'trajectory_lengths': np.array(trajectory_lengths, dtype=np.float64),
        'final_positions': np.array(final_positions, dtype=np.float64),
        'trajectory_curvatures': np.array(trajectory_curvatures, dtype=np.float64),
        'valid_actions': valid_actions,
        'zero_padding_patterns': zero_padding_patterns
    }

def analyze_navsim_comparison(all_comparisons):
    """åˆ†æNavSimå¯¹æ¯”ç»“æœ"""
    if not all_comparisons:
        return None
    
    # æ”¶é›†æ‰€æœ‰è¯¯å·®æ•°æ®
    all_rmse = []
    all_x_rmse = []
    all_y_rmse = []
    all_heading_rmse = []
    all_max_diff = []
    
    for segment_comparisons in all_comparisons:
        for comp in segment_comparisons:
            all_rmse.append(comp['rmse'])
            all_x_rmse.append(comp['x_rmse'])
            all_y_rmse.append(comp['y_rmse'])
            all_heading_rmse.append(comp['heading_rmse'])
            all_max_diff.append(comp['max_diff'])
    
    return {
        'total_comparisons': len(all_rmse),
        'rmse_mean': float(np.mean(all_rmse)),
        'rmse_std': float(np.std(all_rmse)),
        'x_rmse_mean': float(np.mean(all_x_rmse)),
        'x_rmse_std': float(np.std(all_x_rmse)),
        'y_rmse_mean': float(np.mean(all_y_rmse)),
        'y_rmse_std': float(np.std(all_y_rmse)),
        'heading_rmse_mean': float(np.mean(all_heading_rmse)),
        'heading_rmse_std': float(np.std(all_heading_rmse)),
        'max_diff_mean': float(np.mean(all_max_diff)),
        'max_diff_std': float(np.std(all_max_diff)),
        'rmse_range': [float(np.min(all_rmse)), float(np.max(all_rmse))],
        'max_diff_range': [float(np.min(all_max_diff)), float(np.max(all_max_diff))]
    }

def plot_delta_distribution(stats_data, analysis_dir):
    """ç»˜åˆ¶å„æ—¶åˆ»Delta Actionåˆ†å¸ƒå›¾"""
    print("ğŸ“Š ç”ŸæˆDelta Actionåˆ†å¸ƒå›¾...")
    
    # è®¾ç½®ç»˜å›¾é£æ ¼
    plt.style.use('default')
    sns.set_palette("husl")
    
    # åˆ›å»º2x2å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Delta Action Distributions at Different Time Steps', fontsize=16, fontweight='bold')
    
    valid_actions = stats_data['valid_actions']  # (N, 8, 3)
    
    # 1. Xæ–¹å‘åˆ†å¸ƒ (å‰è¿›/åé€€)
    axes[0, 0].set_title('X Direction (Forward/Backward)', fontweight='bold')
    for i in range(8):
        dx_data = valid_actions[:, i, 0]
        axes[0, 0].hist(dx_data, bins=50, alpha=0.6, label=f't={WAYPOINT_TIMES[i]}s', density=True)
    axes[0, 0].set_xlabel('Delta X (m)')
    axes[0, 0].set_ylabel('Density')
    axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Yæ–¹å‘åˆ†å¸ƒ (å·¦è½¬/å³è½¬)
    axes[0, 1].set_title('Y Direction (Left/Right)', fontweight='bold')
    for i in range(8):
        dy_data = valid_actions[:, i, 1]
        axes[0, 1].hist(dy_data, bins=50, alpha=0.6, label=f't={WAYPOINT_TIMES[i]}s', density=True)
    axes[0, 1].set_xlabel('Delta Y (m)')
    axes[0, 1].set_ylabel('Density')
    axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. Yawæ–¹å‘åˆ†å¸ƒ (æ—‹è½¬)
    axes[1, 0].set_title('Yaw Direction (Rotation)', fontweight='bold')
    for i in range(8):
        dyaw_data = valid_actions[:, i, 2]
        axes[1, 0].hist(dyaw_data, bins=50, alpha=0.6, label=f't={WAYPOINT_TIMES[i]}s', density=True)
    axes[1, 0].set_xlabel('Delta Yaw (rad)')
    axes[1, 0].set_ylabel('Density')
    axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. æ—¶é—´åºåˆ—ç»Ÿè®¡ï¼ˆç®±çº¿å›¾ï¼‰
    axes[1, 1].set_title('Delta Statistics Over Time', fontweight='bold')
    
    # å‡†å¤‡ç®±çº¿å›¾æ•°æ®
    dx_means = [np.mean(valid_actions[:, i, 0]) for i in range(8)]
    dy_means = [np.mean(valid_actions[:, i, 1]) for i in range(8)]
    dyaw_means = [np.mean(valid_actions[:, i, 2]) for i in range(8)]
    
    dx_stds = [np.std(valid_actions[:, i, 0]) for i in range(8)]
    dy_stds = [np.std(valid_actions[:, i, 1]) for i in range(8)]
    dyaw_stds = [np.std(valid_actions[:, i, 2]) for i in range(8)]
    
    x_pos = np.array(WAYPOINT_TIMES)
    
    # ç»˜åˆ¶å‡å€¼å’Œæ ‡å‡†å·®
    axes[1, 1].errorbar(x_pos, dx_means, yerr=dx_stds, label='Delta X', marker='o', capsize=5)
    axes[1, 1].errorbar(x_pos, dy_means, yerr=dy_stds, label='Delta Y', marker='s', capsize=5)
    axes[1, 1].errorbar(x_pos, dyaw_means, yerr=dyaw_stds, label='Delta Yaw', marker='^', capsize=5)
    
    axes[1, 1].set_xlabel('Time (s)')
    axes[1, 1].set_ylabel('Delta Value (m for X,Y; rad for Yaw)')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    axes[1, 1].set_xticks(WAYPOINT_TIMES)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    fig_path = os.path.join(analysis_dir, "delta_action_distributions.png")
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ“Š åˆ†å¸ƒå›¾å·²ä¿å­˜: {fig_path}")
    return fig_path

def main():
    print("ğŸš€ å¼€å§‹Actionç”Ÿæˆä¸åˆ†æ...")
    print("ğŸ“ æ–°é€»è¾‘: å…ˆè®¡ç®—Delta Actionsï¼Œå†è®¡ç®—Waypoints (æŒ‰ç…§compareè„šæœ¬)")
    print("ğŸ”§ é…ç½®: Float64 + 0å¡«å…… + NavSimå¯¹æ¯”")
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(ANALYSIS_DIR, exist_ok=True)
    
    # åŠ è½½segments
    segments, metadata = load_segments()
    print(f"ğŸ“ æ€»segmentæ•°: {len(segments)}")
    
    # æ£€æŸ¥NavSimæ•°æ®å¯ç”¨æ€§
    available_navsim_logs = []
    navsim_data_cache = {}
    
    print("ğŸ” æ£€æŸ¥NavSimæ•°æ®å¯ç”¨æ€§...")
    unique_seqs = list(set([s['original_sequence'] for s in segments]))
    print(f"ğŸ“Š NuPlan unique sequences: {len(unique_seqs)}")
    
    # å¿«é€Ÿæ£€æŸ¥å‰å‡ ä¸ªåºåˆ—çš„æ—¥æœŸèŒƒå›´
    sample_seqs = sorted(unique_seqs)[:5]
    print(f"ğŸ“… NuPlanæ ·æœ¬åºåˆ—æ—¥æœŸ: {[seq.split('_')[0] for seq in sample_seqs]}")
    
    # æ£€æŸ¥NavSimæ•°æ®
    navsim_files = os.listdir(NAVSIM_LOGS_PATH) if os.path.exists(NAVSIM_LOGS_PATH) else []
    navsim_seqs = [f.replace('.pkl', '') for f in navsim_files if f.endswith('.pkl')]
    sample_navsim_seqs = sorted(navsim_seqs)[:5]
    print(f"ğŸ“… NavSimæ ·æœ¬åºåˆ—æ—¥æœŸ: {[seq.split('_')[0] for seq in sample_navsim_seqs]}")
    
    # å¯»æ‰¾å…±åŒåºåˆ—
    navsim_seq_set = set(navsim_seqs)
    common_seqs = []
    for seq_name in tqdm(unique_seqs[:100], desc="æ£€æŸ¥åºåˆ—åŒ¹é…"):  # æ£€æŸ¥å‰100ä¸ªåºåˆ—
        if seq_name in navsim_seq_set:
            common_seqs.append(seq_name)
            navsim_data = load_navsim_actions(seq_name)
            navsim_data_cache[seq_name] = navsim_data
            if navsim_data is not None:
                available_navsim_logs.append(seq_name)
    
    print(f"ğŸ“Š å…±åŒåºåˆ—: {len(common_seqs)}")
    print(f"ğŸ“Š å¯ç”¨NavSim logs: {len(available_navsim_logs)}")
    
    if len(common_seqs) == 0:
        print("âš ï¸  å‘ç°ï¼šNuPlanå’ŒNavSimæ•°æ®é›†æ— é‡å åºåˆ—")
        print("ğŸ’¡ è¿™æ„å‘³ç€å®ƒä»¬æ¥è‡ªä¸åŒçš„æ•°æ®æ”¶é›†æ‰¹æ¬¡")
        print("ğŸ”„ å°†è·³è¿‡NavSimå¯¹æ¯”ï¼Œç»§ç»­å¤„ç†NuPlanæ•°æ®")
    
    # å¤„ç†æ¯ä¸ªsegmentçš„actions
    all_actions = []
    all_comparisons = []
    successful_segments = []
    failed_segments = []
    navsim_comparison_count = 0
    
    for segment in tqdm(segments, desc="ç”ŸæˆDelta Actions"):
        actions, waypoints_list = process_segment_actions(segment)
        if actions is not None:
            # ä¿å­˜åˆ°ç‹¬ç«‹çš„.npyæ–‡ä»¶
            save_segment_actions(segment, actions, waypoints_list)
            
            # æ”¶é›†ç”¨äºç»Ÿè®¡åˆ†æ
            all_actions.append(actions)
            successful_segments.append(segment['segment_id'])
            
            # NavSimå¯¹æ¯”ï¼ˆå¦‚æœæ•°æ®å¯ç”¨ï¼‰
            seq_name = segment['original_sequence']
            if seq_name in navsim_data_cache and navsim_data_cache[seq_name] is not None:
                comparisons = compare_with_navsim(segment, actions, navsim_data_cache[seq_name])
                if comparisons:
                    all_comparisons.append(comparisons)
                    navsim_comparison_count += len(comparisons)
        else:
            failed_segments.append(segment['segment_id'])
    
    print(f"âœ… æˆåŠŸå¤„ç†: {len(successful_segments)} ä¸ªsegment")
    print(f"âŒ å¤±è´¥: {len(failed_segments)} ä¸ªsegment")
    print(f"ğŸ”„ NavSimå¯¹æ¯”: {navsim_comparison_count} ä¸ªæ ·æœ¬")
    
    if not all_actions:
        print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†çš„segmentï¼")
        return
    
    # åˆå¹¶æ‰€æœ‰actionsç”¨äºç»Ÿè®¡åˆ†æ
    all_actions_array = np.concatenate(all_actions, axis=0)  # (total_frames, 8, 3)
    print(f"ğŸ“Š æ€»è½¨è¿¹æ•°: {all_actions_array.shape[0]:,}")
    
    # åˆ†æè½¨è¿¹åˆ†å¸ƒ
    stats_data = analyze_trajectory_distribution(all_actions_array)
    trajectory_stats = stats_data['trajectory_stats']
    
    print(f"\nğŸ“Š è½¨è¿¹ç»Ÿè®¡:")
    print(f"  æ€»è½¨è¿¹æ•°: {trajectory_stats['total_trajectories']:,}")
    print(f"  æœ‰æ•ˆè½¨è¿¹æ•°: {trajectory_stats['valid_trajectories']:,}")
    print(f"  å®Œå…¨0å¡«å……è½¨è¿¹æ•°: {trajectory_stats['completely_zero_trajectories']:,}")
    print(f"  æœ‰0å¡«å……è½¨è¿¹æ•°: {trajectory_stats['trajectories_with_zero_padding']:,}")
    print(f"  æ€»åŠ¨ä½œæ•°: {trajectory_stats['total_actions']:,}")
    print(f"  æœ‰0å¡«å……åŠ¨ä½œæ•°: {trajectory_stats['zero_filled_actions']:,}")
    print(f"  0å¡«å……æ¯”ä¾‹: {trajectory_stats['zero_padding_ratio']:.2%}")
    print(f"  è½¨è¿¹0å¡«å……æ¯”ä¾‹: {trajectory_stats['trajectory_zero_padding_ratio']:.2%}")
    print(f"  å¹³å‡è¿ç»­0å¡«å……åŠ¨ä½œæ•°: {trajectory_stats['avg_consecutive_zeros']:.2f}")
    print(f"  å¹³å‡è½¨è¿¹é•¿åº¦: {trajectory_stats['length_mean']:.2f}m")
    print(f"  å¹³å‡æ›²ç‡: {trajectory_stats['curvature_mean']:.3f}rad")
    
    # ç”ŸæˆDeltaåˆ†å¸ƒå¯è§†åŒ–
    plot_delta_distribution(stats_data, ANALYSIS_DIR)
    
    # åˆ†æNavSimå¯¹æ¯”ç»“æœ
    comparison_stats = analyze_navsim_comparison(all_comparisons)
    if comparison_stats:
        print(f"\nğŸ”„ NavSimå¯¹æ¯”ç»Ÿè®¡:")
        print(f"  å¯¹æ¯”æ ·æœ¬æ•°: {comparison_stats['total_comparisons']}")
        print(f"  å¹³å‡RMSE: {comparison_stats['rmse_mean']:.4f}")
        print(f"  Xæ–¹å‘RMSE: {comparison_stats['x_rmse_mean']:.4f}")
        print(f"  Yæ–¹å‘RMSE: {comparison_stats['y_rmse_mean']:.4f}")
        print(f"  æœå‘RMSE: {comparison_stats['heading_rmse_mean']:.4f}")
        print(f"  æœ€å¤§å·®å¼‚: {comparison_stats['max_diff_mean']:.4f}")
    else:
        print(f"\nğŸ”„ NavSimå¯¹æ¯”: æ— å¯æ¯”è¾ƒæ•°æ®ï¼ˆæ•°æ®é›†ä¸é‡å ï¼‰")
    
    # ä¿å­˜ç»Ÿè®¡åˆ†æç»“æœ
    results = {
        'metadata': {
            'processing_method': 'delta_first_then_waypoints',
            'total_segments': len(segments),
            'successful_segments': len(successful_segments),
            'failed_segments': len(failed_segments),
            'total_trajectories': int(all_actions_array.shape[0]),
            'waypoint_times': WAYPOINT_TIMES,
            'zero_padding_enabled': True,
            'float64_precision': True,
            'actions_dir': f"{OUTPUT_DIR}/actions",
            'navsim_comparison_count': navsim_comparison_count,
            'available_navsim_logs': available_navsim_logs,
            'common_sequences_count': len(common_seqs),
            'dataset_overlap': len(common_seqs) > 0,
            'failed_segment_ids': failed_segments[:10]
        },
        'trajectory_stats': stats_data['trajectory_stats'],
        'waypoint_stats': stats_data['waypoint_stats'],
        'navsim_comparison_stats': comparison_stats,
        'action_shape': list(all_actions_array.shape)
    }
    
    # ä¿å­˜ç»Ÿè®¡åˆ†æç»“æœ
    results_file = os.path.join(OUTPUT_DIR, "action_analysis.json")
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    # ä¿å­˜actionsæ•°ç»„
    actions_file = os.path.join(OUTPUT_DIR, "actions_raw.npz")
    np.savez_compressed(actions_file, actions=all_actions_array)
    
    # ä¿å­˜NavSimå¯¹æ¯”è¯¦ç»†ç»“æœ
    if all_comparisons:
        comparison_file = os.path.join(OUTPUT_DIR, "navsim_comparisons.json")
        serializable_comparisons = []
        for segment_comps in all_comparisons:
            for comp in segment_comps:
                serializable_comparisons.append({
                    'image_name': comp['image_name'],
                    'local_frame_idx': comp['local_frame_idx'],
                    'global_frame_idx': comp['global_frame_idx'],
                    'rmse': float(comp['rmse']),
                    'x_rmse': float(comp['x_rmse']),
                    'y_rmse': float(comp['y_rmse']),
                    'heading_rmse': float(comp['heading_rmse']),
                    'max_diff': float(comp['max_diff'])
                })
        
        with open(comparison_file, 'w') as f:
            json.dump(serializable_comparisons, f, indent=2)
        
        print(f"  NavSimå¯¹æ¯”: {comparison_file}")
    
    # æ‰“å°å„æ—¶é—´ç‚¹ç»Ÿè®¡
    print(f"\nğŸ“Š å„æ—¶é—´ç‚¹Delta Actionç»Ÿè®¡:")
    for i in range(8):
        action_key = f'action_{i+1}'
        action_stats = stats_data['waypoint_stats'][action_key]
        time_val = action_stats['time']
        print(f"  {time_val}s: dx={action_stats['dx_mean']:.3f}Â±{action_stats['dx_std']:.3f}m, "
              f"dy={action_stats['dy_mean']:.3f}Â±{action_stats['dy_std']:.3f}m, "
              f"dyaw={action_stats['dyaw_mean']:.3f}Â±{action_stats['dyaw_std']:.3f}rad")
    
    # æ‰“å°æ–‡ä»¶ä½ç½®ä¿¡æ¯
    actions_dir = os.path.join(OUTPUT_DIR, "actions")
    action_files_count = len([f for f in os.listdir(actions_dir) if f.endswith('.npy')])
    
    print(f"\nğŸ’¾ ç»“æœä¿å­˜:")
    print(f"  Actionsæ–‡ä»¶: {actions_dir}/ ({action_files_count} ä¸ª.npyæ–‡ä»¶)")
    print(f"  ç»Ÿè®¡åˆ†æ: {results_file}")
    print(f"  Actionsæ•°ç»„: {actions_file}")
    print(f"  åˆ†å¸ƒå›¾: {ANALYSIS_DIR}/delta_action_distributions.png")
    
    if len(common_seqs) == 0:
        print("âœ… Step 2 å®Œæˆï¼(Delta First + Float64 + 0å¡«å……ï¼ŒNavSimæ•°æ®é›†ä¸é‡å )")
        print("\nğŸ’¡ è¯´æ˜:")
        print("  - NuPlanå’ŒNavSimæ¥è‡ªä¸åŒçš„æ•°æ®æ”¶é›†æ‰¹æ¬¡")
        print("  - æ— æ³•è¿›è¡Œç›´æ¥å¯¹æ¯”ï¼Œä½†æ•°æ®å¤„ç†æˆåŠŸ")
        print("  - å¯ä»¥ä½¿ç”¨ç”Ÿæˆçš„actionsè¿›è¡Œåç»­åˆ†æ")
    else:
        print("âœ… Step 2 å®Œæˆï¼(Delta First + Float64 + 0å¡«å…… + NavSimå¯¹æ¯”)")
        print(f"  ğŸ” NavSimå¯¹æ¯”å®Œæˆï¼Œå‘ç°å¹³å‡RMSE: {comparison_stats['rmse_mean']:.4f}")
    
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print("  è¿è¡Œ step3_analyze_commands.py åˆ†æ20måç§»å’Œç¡®å®šcommandé˜ˆå€¼")
    print(f"  ğŸ’¡ Actionsæ–‡ä»¶ä½ç½®: {actions_dir}/")

if __name__ == "__main__":
    main() 