#!/usr/bin/env python3
"""
æ£€æŸ¥NavSim commandæ˜ å°„å’Œåˆ†å¸ƒ
éªŒè¯left/rightçš„æ­£ç¡®æ€§
"""

import os
import pickle
import numpy as np
from tqdm import tqdm
from collections import Counter

# é…ç½®
NAVSIM_LOGS_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/data/navsim/navsim_logs/mini"

def load_and_analyze_commands():
    """åŠ è½½å¹¶åˆ†æNavSimçš„commandåˆ†å¸ƒ"""
    print("ğŸ” æ£€æŸ¥NavSim commandæ˜ å°„å’Œåˆ†å¸ƒ...")
    
    pkl_files = [f for f in os.listdir(NAVSIM_LOGS_DIR) if f.endswith('.pkl')]
    print(f"æ‰¾åˆ° {len(pkl_files)} ä¸ªæ–‡ä»¶")
    
    all_commands = []
    command_examples = {0: [], 1: [], 2: [], 3: []}
    
    sample_count = 0
    
    for pkl_file in tqdm(pkl_files[:10], desc="åˆ†ææ–‡ä»¶"):  # åªçœ‹å‰10ä¸ªæ–‡ä»¶
        pkl_path = os.path.join(NAVSIM_LOGS_DIR, pkl_file)
        try:
            sequence = pickle.load(open(pkl_path, 'rb'))
            
            for i, frame in enumerate(sequence):
                if sample_count >= 5000:  # é™åˆ¶æ ·æœ¬æ•°
                    break
                    
                driving_command = frame.get('driving_command', None)
                if driving_command is not None:
                    # æ‰¾åˆ°non-zeroçš„index
                    cmd_idx = driving_command.nonzero()[0].item()
                    all_commands.append(cmd_idx)
                    
                    # ä¿å­˜ä¸€äº›ä¾‹å­ç”¨äºåˆ†æ
                    if len(command_examples[cmd_idx]) < 5:
                        command_examples[cmd_idx].append({
                            'file': pkl_file,
                            'frame': i,
                            'command_vector': driving_command.tolist()
                        })
                    
                    sample_count += 1
                
                if sample_count >= 5000:
                    break
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†å¤±è´¥ {pkl_file}: {e}")
            continue
        
        if sample_count >= 5000:
            break
    
    # ç»Ÿè®¡åˆ†å¸ƒ
    command_dist = Counter(all_commands)
    total = sum(command_dist.values())
    
    print(f"\nğŸ“Š Commandåˆ†å¸ƒç»Ÿè®¡ (æ€»è®¡{total:,}ä¸ªæ ·æœ¬):")
    print("="*50)
    for cmd_idx in [0, 1, 2, 3]:
        count = command_dist.get(cmd_idx, 0)
        pct = count / total * 100 if total > 0 else 0
        print(f"Command {cmd_idx}: {count:6d} ({pct:5.1f}%)")
    
    print(f"\nğŸ” Commandå‘é‡ç¤ºä¾‹:")
    print("="*50)
    text_mapping = ["go left", "go straight", "go right", "unknown"]
    
    for cmd_idx in [0, 1, 2, 3]:
        print(f"\nCommand {cmd_idx} ({text_mapping[cmd_idx]}):")
        examples = command_examples[cmd_idx]
        for i, ex in enumerate(examples):
            print(f"  ä¾‹å­{i+1}: {ex['command_vector']} (æ–‡ä»¶: {ex['file'][:30]}..., å¸§: {ex['frame']})")
    
    return command_dist, command_examples

def check_larger_dataset():
    """æ£€æŸ¥æ›´å¤§çš„æ•°æ®é›†"""
    print(f"\nğŸ” æ£€æŸ¥æ›´å¤§çš„NavSimæ•°æ®é›†åˆ†å¸ƒ...")
    
    datasets_to_check = [
        ("test", "/mnt/vdb1/yingyan.li/repo/OmniSim/data/navsim/navsim_logs/test"),
        ("trainval", "/mnt/vdb1/yingyan.li/repo/OmniSim/data/navsim/navsim_logs/trainval")
    ]
    
    results = {}
    
    for dataset_name, dataset_dir in datasets_to_check:
        if os.path.exists(dataset_dir):
            print(f"\nğŸ“ {dataset_name.upper()}æ•°æ®é›†å­˜åœ¨ï¼Œæ£€æŸ¥ä¸­...")
            pkl_files = [f for f in os.listdir(dataset_dir) if f.endswith('.pkl')]
            print(f"{dataset_name.upper()}æ•°æ®é›†æ–‡ä»¶æ•°: {len(pkl_files)}")
            
            # éšæœºé‡‡æ ·ä¸€äº›æ–‡ä»¶
            import random
            sample_files = random.sample(pkl_files, min(10, len(pkl_files)))  # å¢åŠ åˆ°10ä¸ªæ–‡ä»¶
            
            all_commands = []
            sample_count = 0
            
            for pkl_file in tqdm(sample_files, desc=f"åˆ†æ{dataset_name}æ•°æ®"):
                pkl_path = os.path.join(dataset_dir, pkl_file)
                try:
                    sequence = pickle.load(open(pkl_path, 'rb'))
                    
                    for frame in sequence:
                        if sample_count >= 5000:  # å¢åŠ æ ·æœ¬æ•°
                            break
                        
                        driving_command = frame.get('driving_command', None)
                        if driving_command is not None:
                            cmd_idx = driving_command.nonzero()[0].item()
                            all_commands.append(cmd_idx)
                            sample_count += 1
                    
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†å¤±è´¥ {pkl_file}: {e}")
                    continue
                
                if sample_count >= 5000:
                    break
            
            # ç»Ÿè®¡æ•°æ®åˆ†å¸ƒ
            command_dist = Counter(all_commands)
            total = sum(command_dist.values())
            
            print(f"\nğŸ“Š {dataset_name.upper()}æ•°æ®é›†Commandåˆ†å¸ƒ (æ€»è®¡{total:,}ä¸ªæ ·æœ¬):")
            print("="*50)
            for cmd_idx in [0, 1, 2, 3]:
                count = command_dist.get(cmd_idx, 0)
                pct = count / total * 100 if total > 0 else 0
                print(f"Command {cmd_idx}: {count:6d} ({pct:5.1f}%)")
            
            results[dataset_name] = command_dist
            
        else:
            print(f"âŒ {dataset_name.upper()}æ•°æ®é›†ä¸å­˜åœ¨")
    
    return results

def main():
    print("ğŸš€ å¼€å§‹æ£€æŸ¥NavSim commandæ˜ å°„...")
    
    # 1. æ£€æŸ¥miniæ•°æ®é›†
    mini_dist, examples = load_and_analyze_commands()
    
    # 2. æ£€æŸ¥testå’Œtrainvalæ•°æ®é›†
    larger_datasets = check_larger_dataset()
    
    # 3. æ€»ç»“åˆ†æ
    print(f"\n" + "="*60)
    print(f"ğŸ“‹ æ€»ç»“åˆ†æ:")
    print(f"="*60)
    
    print(f"\nğŸ’¡ Commandæ˜ å°„éªŒè¯:")
    print(f"  0 -> go left")
    print(f"  1 -> go straight") 
    print(f"  2 -> go right")
    print(f"  3 -> unknown")
    
    print(f"\nğŸ“Š æ•°æ®é›†å¯¹æ¯”:")
    print(f"{'æ•°æ®é›†':<10} {'LEFT%':<8} {'STRAIGHT%':<12} {'RIGHT%':<8} {'UNKNOWN%':<8}")
    print("-" * 50)
    
    # Miniæ•°æ®é›†
    mini_total = sum(mini_dist.values())
    mini_left = mini_dist.get(0, 0) / mini_total * 100
    mini_straight = mini_dist.get(1, 0) / mini_total * 100
    mini_right = mini_dist.get(2, 0) / mini_total * 100
    mini_unknown = mini_dist.get(3, 0) / mini_total * 100
    
    print(f"{'Mini':<10} {mini_left:<8.1f} {mini_straight:<12.1f} {mini_right:<8.1f} {mini_unknown:<8.1f}")
    
    # å…¶ä»–æ•°æ®é›†
    for dataset_name, dataset_dist in larger_datasets.items():
        if dataset_dist:
            total = sum(dataset_dist.values())
            left = dataset_dist.get(0, 0) / total * 100
            straight = dataset_dist.get(1, 0) / total * 100
            right = dataset_dist.get(2, 0) / total * 100
            unknown = dataset_dist.get(3, 0) / total * 100
            
            print(f"{dataset_name.capitalize():<10} {left:<8.1f} {straight:<12.1f} {right:<8.1f} {unknown:<8.1f}")
    
    print(f"\nğŸ¤” ç”¨æˆ·ç–‘é—®åˆ†æ:")
    if mini_left > mini_right:
        print(f"  â“ æ‰€æœ‰æ•°æ®é›†éƒ½æ˜¾ç¤ºå·¦è½¬å¤šäºå³è½¬:")
        print(f"     Mini: å·¦è½¬{mini_left:.1f}% vs å³è½¬{mini_right:.1f}%")
        
        for dataset_name, dataset_dist in larger_datasets.items():
            if dataset_dist:
                total = sum(dataset_dist.values())
                left = dataset_dist.get(0, 0) / total * 100
                right = dataset_dist.get(2, 0) / total * 100
                print(f"     {dataset_name.capitalize()}: å·¦è½¬{left:.1f}% vs å³è½¬{right:.1f}%")
        
        print(f"\n  ğŸ’­ å¯èƒ½åŸå› :")
        print(f"     1. NavSimåŸºäºçœŸå®é©¾é©¶æ•°æ®ï¼Œåæ˜ å®é™…è·¯ç½‘ç‰¹å¾")
        print(f"     2. ç¾å›½ç­‰å³ä¾§é€šè¡Œå›½å®¶ï¼Œå·¦è½¬æ›´å¤æ‚ï¼Œæ ‡æ³¨æ›´å¤š")
        print(f"     3. æ•°æ®é‡‡é›†è·¯çº¿åå‘åŸå¸‚/å¤æ‚è·¯æ®µ")
        print(f"     4. å·¦è½¬éœ€è¦æ›´å¤šdecision-makingï¼Œè¢«ç‰¹åˆ«æ ‡æ³¨")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ•°æ®é›†å³è½¬æ›´å¤š
    right_more_datasets = []
    for dataset_name, dataset_dist in larger_datasets.items():
        if dataset_dist:
            total = sum(dataset_dist.values())
            left = dataset_dist.get(0, 0) / total * 100
            right = dataset_dist.get(2, 0) / total * 100
            if right > left:
                right_more_datasets.append(dataset_name)
    
    if right_more_datasets:
        print(f"  âœ… ä»¥ä¸‹æ•°æ®é›†æ˜¾ç¤ºå³è½¬æ›´å¤š: {', '.join(right_more_datasets)}")
    else:
        print(f"  ğŸ¤· æ‰€æœ‰æ£€æŸ¥çš„æ•°æ®é›†éƒ½æ˜¾ç¤ºå·¦è½¬æ›´å¤šï¼Œä¸ä¸€èˆ¬ç›´è§‰ä¸åŒ")
        print(f"  ğŸ“ å»ºè®®: è¿™å¯èƒ½ç¡®å®æ˜¯NavSimæ•°æ®çš„ç‰¹å¾ï¼Œéœ€è¦æ¥å—è¿™ä¸ªç°å®")

if __name__ == "__main__":
    main() 