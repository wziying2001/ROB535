#!/usr/bin/env python3
"""
NuPlanè§†é¢‘åˆ†å‰²è„šæœ¬ - Step 1
å°†é•¿è§†é¢‘åˆ‡åˆ†æˆçŸ­è§†é¢‘æ®µï¼Œè€ƒè™‘actionç”Ÿæˆçš„è¾¹ç•Œæ¡ä»¶
æ£€æŸ¥imgå’Œnpyæ–‡ä»¶å­˜åœ¨æ€§
ä¸¥æ ¼æŒ‰ç…§JSONä¸­çš„imagesé¡ºåºå¤„ç†ï¼Œä¸è¿›è¡Œä»»ä½•æ’åº
"""

import os
import json
import glob
from tqdm import tqdm

# é…ç½®
NUPLAN_JSON_DIR = "/mnt/vdb1/nuplan_json"
NUPLAN_IMAGES_DIR = "/mnt/vdb1/nuplan/images"
NUPLAN_VQ_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/data/nuplan/processed_data/vq_codes_merge"
EXCLUDE_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/data/navsim/processed_data/test_vq_codes"
OUTPUT_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/intermediate"

SAMPLING_RATE = 10.0  # Hz
SEGMENT_LENGTH_SECONDS = 20
MIN_SEGMENT_SECONDS = 8
FUTURE_HORIZON_SECONDS = 4  # éœ€è¦æœªæ¥4ç§’æ¥ç”Ÿæˆwaypointsï¼ˆä½†ç°åœ¨ä¼šç”¨0å¡«å……ï¼‰

def get_exclude_list():
    """è·å–è¦æ’é™¤çš„åºåˆ—åˆ—è¡¨"""
    exclude_set = set()
    if os.path.exists(EXCLUDE_DIR):
        for seq_name in os.listdir(EXCLUDE_DIR):
            if os.path.isdir(os.path.join(EXCLUDE_DIR, seq_name)):
                exclude_set.add(seq_name)
    return exclude_set

def get_all_image_logs():
    """è·å–imagesç›®å½•ä¸‹çš„æ‰€æœ‰logç›®å½•"""
    image_logs = set()
    if not os.path.exists(NUPLAN_IMAGES_DIR):
        print(f"âŒ Imagesç›®å½•ä¸å­˜åœ¨: {NUPLAN_IMAGES_DIR}")
        return image_logs
    
    for item in os.listdir(NUPLAN_IMAGES_DIR):
        item_path = os.path.join(NUPLAN_IMAGES_DIR, item)
        if os.path.isdir(item_path):
            cam_f0_path = os.path.join(item_path, "CAM_F0")
            if os.path.exists(cam_f0_path):
                image_logs.add(item)
    
    return image_logs

def validate_log_completeness(seq_name):
    """éªŒè¯å•ä¸ªlogçš„ä¸‰ä¸ªç»„ä»¶ï¼ˆimages, JSON, VQï¼‰æ˜¯å¦éƒ½å­˜åœ¨"""
    images_path = os.path.join(NUPLAN_IMAGES_DIR, seq_name, "CAM_F0")
    images_exist = os.path.exists(images_path)
    jpg_count = len(glob.glob(os.path.join(images_path, "*.jpg"))) if images_exist else 0
    
    json_path = os.path.join(NUPLAN_JSON_DIR, f"{seq_name}.json")
    json_exists = os.path.exists(json_path)
    
    vq_path = os.path.join(NUPLAN_VQ_DIR, seq_name)
    vq_exists = os.path.exists(vq_path)
    npy_count = len(glob.glob(os.path.join(vq_path, "*.npy"))) if vq_exists else 0
    
    return {
        'seq_name': seq_name,
        'images_exist': images_exist,
        'json_exists': json_exists,
        'vq_exists': vq_exists,
        'jpg_count': jpg_count,
        'npy_count': npy_count,
        'is_complete': images_exist and json_exists and vq_exists,
        'json_path': json_path if json_exists else None
    }

def validate_image_and_vq_paths(image_paths, seq_name):
    """éªŒè¯å›¾ç‰‡å’Œå¯¹åº”npyæ–‡ä»¶æ˜¯å¦éƒ½å­˜åœ¨ï¼Œä¸¥æ ¼æŒ‰ç…§JSONé¡ºåº"""
    valid_pairs = []
    missing_img_count = 0
    missing_npz_count = 0
    missing_both_count = 0
    
    # ç›´æ¥æŒ‰ç…§JSONä¸­çš„é¡ºåºå¤„ç†ï¼Œä¸è¿›è¡Œæ’åº
    for img_path in image_paths:
        img_filename = os.path.basename(img_path)
        
        # å›¾ç‰‡æ–‡ä»¶å®Œæ•´è·¯å¾„
        img_full_path = os.path.join(NUPLAN_IMAGES_DIR, seq_name, "CAM_F0", img_filename)
        img_exists = os.path.exists(img_full_path)
        
        # å¯¹åº”çš„npyæ–‡ä»¶è·¯å¾„
        npy_filename = img_filename.replace('.jpg', '.npy')
        npy_full_path = os.path.join(NUPLAN_VQ_DIR, seq_name, npy_filename)
        npy_exists = os.path.exists(npy_full_path)
        
        # ç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
        if not img_exists and not npy_exists:
            missing_both_count += 1
        elif not img_exists:
            missing_img_count += 1
        elif not npy_exists:
            missing_npz_count += 1
        else:
            # ä¸¤ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨ï¼Œæ·»åŠ åˆ°æœ‰æ•ˆåˆ—è¡¨
            valid_pairs.append({
                'img_path': os.path.join(seq_name, "CAM_F0", img_filename),
                'npy_path': os.path.join(seq_name, npy_filename)
            })
    
    return valid_pairs, {
        'missing_img': missing_img_count,
        'missing_npz': missing_npz_count,
        'missing_both': missing_both_count,
        'total_missing': missing_img_count + missing_npz_count + missing_both_count
    }

def calculate_valid_segments(total_frames):
    """è®¡ç®—æœ‰æ•ˆçš„è§†é¢‘æ®µï¼Œç°åœ¨ä¸æ’é™¤æœ€åçš„å¸§ï¼ˆå› ä¸ºä¼šç”¨0å¡«å……actionï¼‰"""
    min_frames = int(MIN_SEGMENT_SECONDS * SAMPLING_RATE)  # 80å¸§
    segment_frames = int(SEGMENT_LENGTH_SECONDS * SAMPLING_RATE)  # 200å¸§
    
    if total_frames < min_frames:
        return []
    
    segments = []
    if total_frames >= segment_frames:
        # åˆ‡åˆ†20ç§’æ®µ
        for start in range(0, total_frames, segment_frames):
            end = min(start + segment_frames, total_frames)
            if end - start >= min_frames:
                segments.append((start, end))
    elif total_frames >= min_frames:
        # 8-20ç§’ï¼Œä¿ç•™ä¸ºä¸€æ®µ
        segments.append((0, total_frames))
    
    return segments

def process_sequence(seq_name, json_path):
    """å¤„ç†å•ä¸ªåºåˆ—ï¼Œä¸¥æ ¼æŒ‰ç…§JSONé¡ºåº"""
    try:
        with open(json_path, 'r') as f:
            json_data = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–JSONå¤±è´¥: {json_path}")
        return [], {}
    
    image_list = json_data.get('images', [])
    if not image_list:
        return [], {}
    
    # ä¸¥æ ¼æŒ‰ç…§JSONä¸­çš„é¡ºåºï¼Œä¸è¿›è¡Œä»»ä½•æ’åº
    print(f"ğŸ“„ {seq_name}: JSONè®°å½•{len(image_list)}å¼ å›¾ç‰‡ï¼ŒæŒ‰åŸå§‹é¡ºåºå¤„ç†")
    
    # éªŒè¯å›¾ç‰‡å’Œnpyæ–‡ä»¶è·¯å¾„
    valid_pairs, missing_stats = validate_image_and_vq_paths(image_list, seq_name)
    
    if missing_stats['total_missing'] > 0:
        missing_details = []
        if missing_stats['missing_img'] > 0:
            missing_details.append(f"{missing_stats['missing_img']} å¼ å›¾ç‰‡")
        if missing_stats['missing_npz'] > 0:
            missing_details.append(f"{missing_stats['missing_npz']} ä¸ªnpyæ–‡ä»¶")
        if missing_stats['missing_both'] > 0:
            missing_details.append(f"{missing_stats['missing_both']} å¯¹æ–‡ä»¶éƒ½ç¼ºå¤±")
        
        print(f"âš ï¸ {seq_name}: ç¼ºå¤± {' + '.join(missing_details)}")
    
    if len(valid_pairs) == 0:
        return [], missing_stats
    
    # è®¡ç®—æœ‰æ•ˆåˆ†å‰²æ®µ
    segments = calculate_valid_segments(len(valid_pairs))
    if not segments:
        return [], missing_stats
    
    # ç”Ÿæˆåˆ†å‰²æ®µä¿¡æ¯
    segment_infos = []
    for seg_idx, (start_frame, end_frame) in enumerate(segments):
        segment_id = f"{seq_name}_seg_{seg_idx:03d}"
        frame_count = end_frame - start_frame
        duration_seconds = frame_count / SAMPLING_RATE
        
        # æå–è¯¥æ®µçš„æ–‡ä»¶è·¯å¾„ï¼ˆä¿æŒJSONåŸå§‹é¡ºåºï¼‰
        segment_pairs = valid_pairs[start_frame:end_frame]
        segment_images = [pair['img_path'] for pair in segment_pairs]
        segment_npy = [pair['npy_path'] for pair in segment_pairs]
        
        segment_info = {
            "segment_id": segment_id,
            "original_sequence": seq_name,
            "start_frame": start_frame,
            "end_frame": end_frame,
            "frame_count": frame_count,
            "duration_seconds": duration_seconds,
            "image_paths": segment_images,
            "npy_paths": segment_npy
        }
        segment_infos.append(segment_info)
    
    return segment_infos, missing_stats

def main():
    print("ğŸš€ å¼€å§‹å¤„ç†NuPlanè§†é¢‘åˆ†å‰²...")
    print("ğŸ” ä»¥imagesç›®å½•ä¸ºåŸºå‡†ï¼ŒéªŒè¯JSONå’ŒVQæ–‡ä»¶å­˜åœ¨æ€§...")
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # è·å–æ’é™¤åˆ—è¡¨
    exclude_set = get_exclude_list()
    print(f"ğŸ“‹ æ’é™¤åºåˆ—æ•°é‡: {len(exclude_set)}")
    
    # è·å–æ‰€æœ‰image logsï¼ˆä»¥imagesä¸ºåŸºå‡†ï¼‰
    image_logs = get_all_image_logs()
    print(f"ğŸ“ Imagesç›®å½•æ€»logæ•°: {len(image_logs)}")
    
    # éªŒè¯æ¯ä¸ªlogçš„å®Œæ•´æ€§
    print("ğŸ” éªŒè¯å„ç»„ä»¶å­˜åœ¨æ€§...")
    complete_logs = []
    incomplete_logs = []
    
    for seq_name in tqdm(sorted(image_logs), desc="éªŒè¯å®Œæ•´æ€§"):
        if seq_name in exclude_set:
            continue
        
        validation = validate_log_completeness(seq_name)
        if validation['is_complete']:
            complete_logs.append(validation)
        else:
            incomplete_logs.append(validation)
    
    print(f"âœ… å®Œæ•´çš„logæ•°: {len(complete_logs)}")
    print(f"âŒ ä¸å®Œæ•´çš„logæ•°: {len(incomplete_logs)}")
    
    # æ˜¾ç¤ºä¸å®Œæ•´logçš„è¯¦æƒ…
    if incomplete_logs:
        print("\nâš ï¸ ä¸å®Œæ•´çš„logè¯¦æƒ…:")
        for item in incomplete_logs[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            missing_parts = []
            if not item['images_exist']:
                missing_parts.append("Images")
            if not item['json_exists']:
                missing_parts.append("JSON")
            if not item['vq_exists']:
                missing_parts.append("VQ")
            
            print(f"  {item['seq_name']}: ç¼ºå¤± {', '.join(missing_parts)}")
            print(f"    JPG: {item['jpg_count']}, NPY: {item['npy_count']}")
        
        if len(incomplete_logs) > 10:
            print(f"    ... è¿˜æœ‰ {len(incomplete_logs) - 10} ä¸ªä¸å®Œæ•´log")
    
    # å¤„ç†å®Œæ•´çš„log
    stats = {
        'total_image_logs': len(image_logs),
        'excluded_sequences': len([seq for seq in image_logs if seq in exclude_set]),
        'complete_logs': len(complete_logs),
        'incomplete_logs': len(incomplete_logs),
        'processed_sequences': 0,
        'total_segments': 0,
        'file_stats': {
            'total_img_files': 0,
            'total_npy_files': 0,
            'missing_img_files': 0,
            'missing_npy_files': 0,
            'missing_both_files': 0,
            'valid_pairs': 0
        }
    }
    
    all_segments = []
    
    # å¤„ç†æ¯ä¸ªå®Œæ•´çš„log
    for validation in tqdm(complete_logs, desc="å¤„ç†åºåˆ—"):
        seq_name = validation['seq_name']
        json_path = validation['json_path']
        
        segments, missing_stats = process_sequence(seq_name, json_path)
        
        # ç´¯ç§¯æ–‡ä»¶ç»Ÿè®¡
        stats['file_stats']['missing_img_files'] += missing_stats.get('missing_img', 0)
        stats['file_stats']['missing_npy_files'] += missing_stats.get('missing_npz', 0)
        stats['file_stats']['missing_both_files'] += missing_stats.get('missing_both', 0)
        
        if segments:
            all_segments.extend(segments)
            stats['processed_sequences'] += 1
            stats['total_segments'] += len(segments)
    
    # è®¡ç®—æœ€ç»ˆçš„æ–‡ä»¶ç»Ÿè®¡
    total_img_files = 0
    total_npy_files = 0
    
    for segment in all_segments:
        total_img_files += len(segment['image_paths'])
        total_npy_files += len(segment['npy_paths'])
    
    stats['file_stats']['total_img_files'] = total_img_files
    stats['file_stats']['total_npy_files'] = total_npy_files
    stats['file_stats']['valid_pairs'] = total_img_files  # åº”è¯¥ç›¸ç­‰
    
    # ä¿å­˜ç»“æœ
    output_data = {
        "metadata": {
            "sampling_rate": SAMPLING_RATE,
            "segment_length_seconds": SEGMENT_LENGTH_SECONDS,
            "min_segment_seconds": MIN_SEGMENT_SECONDS,
            "future_horizon_seconds": FUTURE_HORIZON_SECONDS,
            "processing_approach": "images_based_validation",
            "vq_source": "vq_codes_merge",
            "processing_stats": stats
        },
        "segments": all_segments
    }
    
    output_file = os.path.join(OUTPUT_DIR, "video_segments.json")
    with open(output_file, 'w') as f:
        json.dump(output_data, f, indent=2)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š å¤„ç†ç»“æœ:")
    print(f"Imagesæ€»logæ•°: {stats['total_image_logs']}")
    print(f"æ’é™¤åºåˆ—æ•°: {stats['excluded_sequences']}")
    print(f"å®Œæ•´logæ•°: {stats['complete_logs']}")
    print(f"ä¸å®Œæ•´logæ•°: {stats['incomplete_logs']}")
    print(f"æˆåŠŸå¤„ç†: {stats['processed_sequences']}")
    print(f"ç”Ÿæˆæ®µæ•°: {stats['total_segments']}")
    
    print(f"\nğŸ“ æ–‡ä»¶ç»Ÿè®¡:")
    print(f"æœ‰æ•ˆimgæ–‡ä»¶: {stats['file_stats']['total_img_files']:,}")
    print(f"æœ‰æ•ˆnpyæ–‡ä»¶: {stats['file_stats']['total_npy_files']:,}")
    print(f"æœ‰æ•ˆæ–‡ä»¶å¯¹: {stats['file_stats']['valid_pairs']:,}")
    
    if any(v > 0 for v in [stats['file_stats']['missing_img_files'], 
                          stats['file_stats']['missing_npy_files'], 
                          stats['file_stats']['missing_both_files']]):
        print(f"\nâš ï¸ ç¼ºå¤±æ–‡ä»¶ç»Ÿè®¡:")
        if stats['file_stats']['missing_img_files'] > 0:
            print(f"ç¼ºå¤±imgæ–‡ä»¶: {stats['file_stats']['missing_img_files']:,}")
        if stats['file_stats']['missing_npy_files'] > 0:
            print(f"ç¼ºå¤±npyæ–‡ä»¶: {stats['file_stats']['missing_npy_files']:,}")
        if stats['file_stats']['missing_both_files'] > 0:
            print(f"ä¸¤è€…éƒ½ç¼ºå¤±: {stats['file_stats']['missing_both_files']:,}")
    
    if all_segments:
        import numpy as np
        durations = [seg['duration_seconds'] for seg in all_segments]
        print(f"\nâ±ï¸ æ®µé•¿ç»Ÿè®¡:")
        print(f"å¹³å‡æ®µé•¿: {np.mean(durations):.1f}s")
        print(f"æœ€çŸ­æ®µé•¿: {np.min(durations):.1f}s")
        print(f"æœ€é•¿æ®µé•¿: {np.max(durations):.1f}s")
    
    print(f"\nğŸ’¾ ç»“æœä¿å­˜åˆ°: {output_file}")
    print("âœ… Step 1 å®Œæˆï¼")

if __name__ == "__main__":
    main() 