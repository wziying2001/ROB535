#!/usr/bin/env python3
"""
NuPlan Poseè´¨é‡æ£€æŸ¥è„šæœ¬
æ£€æŸ¥åŸå§‹JSONæ–‡ä»¶ä¸­çš„poseæ•°æ®è´¨é‡é—®é¢˜ï¼Œè¯†åˆ«åå¸§å¹¶è®°å½•
åªæ£€æŸ¥video_segments.jsonä¸­å®é™…ä½¿ç”¨çš„åºåˆ—
"""

import os
import json
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# é…ç½®
NUPLAN_JSON_DIR = "/mnt/vdb1/nuplan_json"
SEGMENTS_JSON = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/intermediate/video_segments.json"
OUTPUT_DIR = "/mnt/vdb1/yingyan.li/repo/OmniSim/dataprocess/analysis/pose_quality"
REPORT_FILE = "pose_quality_report.json"
SUMMARY_FILE = "pose_quality_summary.txt"

# é˜ˆå€¼é…ç½®
THRESHOLDS = {
    'max_displacement_per_frame': 5.0,      # æœ€å¤§å¸§é—´ä½ç§» (m)
    'max_rotation_per_frame': 0.3,          # æœ€å¤§å¸§é—´æ—‹è½¬ (rad)
    'max_z_displacement': 2.0,              # æœ€å¤§Zè½´ä½ç§» (m)
    'max_velocity': 50.0,                   # æœ€å¤§é€Ÿåº¦ (m/s, assuming 10Hz)
    'max_acceleration': 10.0,               # æœ€å¤§åŠ é€Ÿåº¦ (m/sÂ²)
    'min_det_threshold': 0.01,              # å˜æ¢çŸ©é˜µè¡Œåˆ—å¼æœ€å°å€¼
    'max_det_threshold': 100.0,             # å˜æ¢çŸ©é˜µè¡Œåˆ—å¼æœ€å¤§å€¼
}

def load_used_sequences():
    """åŠ è½½video_segments.jsonä¸­å®é™…ä½¿ç”¨çš„åºåˆ—åç§°"""
    print("ğŸ“‹ åŠ è½½å®é™…ä½¿ç”¨çš„åºåˆ—...")
    with open(SEGMENTS_JSON, 'r') as f:
        data = json.load(f)
    
    used_sequences = set([seg['original_sequence'] for seg in data['segments']])
    print(f"  ğŸ“Š å®é™…ä½¿ç”¨çš„åºåˆ—æ•°é‡: {len(used_sequences)}")
    return used_sequences

def validate_transformation_matrix(pose):
    """éªŒè¯4x4å˜æ¢çŸ©é˜µçš„æ•°å­¦æœ‰æ•ˆæ€§"""
    try:
        pose = np.array(pose, dtype=np.float64)
        if pose.shape != (4, 4):
            return False, "Invalid shape"
        
        # æ£€æŸ¥æ—‹è½¬çŸ©é˜µéƒ¨åˆ† (3x3)
        rotation = pose[:3, :3]
        
        # è®¡ç®—è¡Œåˆ—å¼ï¼Œåº”è¯¥æ¥è¿‘1
        det = np.linalg.det(rotation)
        if abs(det - 1.0) > 0.1:
            return False, f"Invalid rotation determinant: {det:.4f}"
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ­£äº¤çŸ©é˜µ R^T * R = I
        should_be_identity = rotation.T @ rotation
        identity = np.eye(3)
        if not np.allclose(should_be_identity, identity, atol=0.1):
            return False, "Not orthogonal matrix"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–inf
        if np.any(np.isnan(pose)) or np.any(np.isinf(pose)):
            return False, "Contains NaN or inf"
        
        # æ£€æŸ¥åº•è¡Œæ˜¯å¦ä¸º [0, 0, 0, 1]
        if not np.allclose(pose[3, :], [0, 0, 0, 1], atol=0.01):
            return False, f"Invalid bottom row: {pose[3, :]}"
        
        return True, "Valid"
    
    except Exception as e:
        return False, f"Exception: {str(e)}"

def calculate_pose_metrics(poses):
    """è®¡ç®—poseåºåˆ—çš„å„ç§æŒ‡æ ‡"""
    poses_array = np.array(poses, dtype=np.float64)
    num_frames = len(poses_array)
    
    if num_frames < 2:
        return {}
    
    # æå–ä½ç½®å’Œæ—‹è½¬
    positions = poses_array[:, :3, 3]  # (N, 3)
    
    # è®¡ç®—å¸§é—´ä½ç§»
    displacements = np.linalg.norm(np.diff(positions, axis=0), axis=1)  # (N-1,)
    
    # è®¡ç®—é€Ÿåº¦ (å‡è®¾10Hzé‡‡æ ·)
    velocities = displacements * 10.0  # m/s
    
    # è®¡ç®—åŠ é€Ÿåº¦
    accelerations = np.diff(velocities) * 10.0 if len(velocities) > 1 else np.array([])
    
    # è®¡ç®—æ—‹è½¬è§’åº¦å˜åŒ–
    rotation_changes = []
    for i in range(num_frames - 1):
        R1 = poses_array[i, :3, :3]
        R2 = poses_array[i + 1, :3, :3]
        # è®¡ç®—ç›¸å¯¹æ—‹è½¬
        R_rel = R1.T @ R2
        # æå–æ—‹è½¬è§’åº¦
        trace = np.trace(R_rel)
        # é¿å…æ•°å€¼è¯¯å·®
        trace = np.clip(trace, -1, 3)
        angle = np.arccos((trace - 1) / 2)
        rotation_changes.append(angle)
    
    rotation_changes = np.array(rotation_changes)
    
    return {
        'positions': positions,
        'displacements': displacements,
        'velocities': velocities,
        'accelerations': accelerations,
        'rotation_changes': rotation_changes,
        'z_positions': positions[:, 2],
        'z_changes': np.diff(positions[:, 2])
    }

def check_sequence_quality(seq_name, poses):
    """æ£€æŸ¥ä¸€ä¸ªsequenceçš„poseè´¨é‡ - ç®€åŒ–ç‰ˆ"""
    issues = []
    
    # è®¾ç½®é˜ˆå€¼ - poseä¸­xã€yä½ç§»è¶…è¿‡æ­¤å€¼å°±è®°å½•
    POSE_TRANSLATION_THRESHOLD = 5.0
    
    # æ£€æŸ¥æ¯ä¸ªposeçš„xã€yä½ç§»æ˜¯å¦è¶…è¿‡é˜ˆå€¼
    for i, pose in enumerate(poses):
        try:
            pose_array = np.array(pose, dtype=np.float64)
            
            # æå–ä½ç½®ä¿¡æ¯ (x, y, z) - poseçŸ©é˜µçš„å¹³ç§»éƒ¨åˆ†
            position = pose_array[:3, 3]
            x, y, z = position
            
            # æ£€æŸ¥xã€yä½ç§»æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            if abs(x) > POSE_TRANSLATION_THRESHOLD or abs(y) > POSE_TRANSLATION_THRESHOLD:
                issues.append({
                    'type': 'large_pose_translation',
                    'frame': i,
                    'position': [float(x), float(y), float(z)],
                    'threshold': POSE_TRANSLATION_THRESHOLD,
                    'message': f"Frame {i}: Large pose translation x={x:.3f}, y={y:.3f} (threshold={POSE_TRANSLATION_THRESHOLD})",
                    'original_pose': pose  # ä¿å­˜å®Œæ•´çš„åŸå§‹pose
                })
        except Exception as e:
            # å¦‚æœposeæ ¼å¼æœ‰é—®é¢˜ï¼Œä¹Ÿè®°å½•
            issues.append({
                'type': 'invalid_pose_format',
                'frame': i,
                'message': f"Frame {i}: Invalid pose format - {str(e)}",
                'original_pose': pose  # ä¿å­˜åŸå§‹pose
            })
    
    # ç®€å•çš„ç»Ÿè®¡ä¿¡æ¯
    metrics = {
        'total_frames': len(poses),
        'problematic_frames': len(issues)
    }
    
    return issues, metrics

def generate_visualizations(all_metrics, bad_sequences, output_dir):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ - ç®€åŒ–ç‰ˆ"""
    print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # ç®€åŒ–ç‰ˆçš„å¯è§†åŒ–
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    fig.suptitle('NuPlan Pose Quality Analysis (Simplified)', fontsize=16, fontweight='bold')
    
    # 1. åºåˆ—é—®é¢˜ç»Ÿè®¡
    total_sequences = len(all_metrics)
    problem_sequences = len(bad_sequences)
    good_sequences = total_sequences - problem_sequences
    
    labels = ['Good Sequences', 'Problem Sequences']
    sizes = [good_sequences, problem_sequences]
    colors = ['#2ecc71', '#e74c3c']
    
    axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
    axes[0].set_title('Sequence Quality Distribution')
    
    # 2. é—®é¢˜ç±»å‹ç»Ÿè®¡
    issue_types = defaultdict(int)
    for seq_issues in bad_sequences.values():
        for issue in seq_issues:
            issue_types[issue['type']] += 1
    
    if issue_types:
        types = list(issue_types.keys())
        counts = list(issue_types.values())
        axes[1].bar(types, counts, alpha=0.7, edgecolor='black', color='#3498db')
        axes[1].set_xlabel('Issue Type')
        axes[1].set_ylabel('Count')
        axes[1].set_title('Distribution of Pose Issues')
        axes[1].tick_params(axis='x', rotation=45)
        axes[1].grid(True, alpha=0.3)
    else:
        axes[1].text(0.5, 0.5, 'No issues found', ha='center', va='center', 
                    transform=axes[1].transAxes, fontsize=14)
        axes[1].set_title('Distribution of Pose Issues')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    plot_file = os.path.join(output_dir, "pose_quality_analysis.png")
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"  ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {plot_file}")

def main():
    print("ğŸ” å¼€å§‹NuPlan Poseè´¨é‡æ£€æŸ¥ (ä»…æ£€æŸ¥å®é™…ä½¿ç”¨çš„åºåˆ—)...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åŠ è½½å®é™…ä½¿ç”¨çš„åºåˆ—
    used_sequences = load_used_sequences()
    
    # æ£€æŸ¥ç»“æœ
    all_results = {}
    bad_sequences = {}
    all_metrics = {}
    total_issues = 0
    missing_sequences = []
    
    print("ğŸ”„ é€ä¸ªæ£€æŸ¥å®é™…ä½¿ç”¨çš„åºåˆ—...")
    for seq_name in tqdm(used_sequences, desc="æ£€æŸ¥åºåˆ—"):
        json_path = os.path.join(NUPLAN_JSON_DIR, f"{seq_name}.json")
        
        if not os.path.exists(json_path):
            print(f"âš ï¸ åºåˆ—æ–‡ä»¶ä¸å­˜åœ¨: {seq_name}")
            missing_sequences.append(seq_name)
            continue
        
        try:
            with open(json_path, 'r') as f:
                data = json.load(f)
            
            poses = data.get('poses', [])
            if not poses:
                continue
            
            # æ£€æŸ¥è´¨é‡
            issues, metrics = check_sequence_quality(seq_name, poses)
            
            # è®°å½•ç»“æœ
            all_results[seq_name] = {
                'total_frames': len(poses),
                'issues_count': len(issues),
                'issues': issues
            }
            
            if metrics:
                all_metrics[seq_name] = metrics
            
            if issues:
                bad_sequences[seq_name] = issues
                total_issues += len(issues)
        
        except Exception as e:
            print(f"âŒ å¤„ç† {seq_name} æ—¶å‡ºé”™: {str(e)}")
            all_results[seq_name] = {
                'error': str(e)
            }
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("ğŸ“‹ ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_sequences = len(all_results)
    bad_sequences_count = len(bad_sequences)
    good_sequences_count = total_sequences - bad_sequences_count
    
    # é—®é¢˜ç±»å‹ç»Ÿè®¡
    issue_type_stats = defaultdict(int)
    severity_stats = {'critical': 0, 'warning': 0}
    
    for seq_name, issues in bad_sequences.items():
        for issue in issues:
            issue_type_stats[issue['type']] += 1
            
            # åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
            if issue['type'] in ['invalid_matrix', 'excessive_displacement', 'excessive_velocity']:
                severity_stats['critical'] += 1
            else:
                severity_stats['warning'] += 1
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report_data = {
        'summary': {
            'total_used_sequences': len(used_sequences),
            'total_checked_sequences': total_sequences,
            'missing_sequences': len(missing_sequences),
            'good_sequences': good_sequences_count,
            'bad_sequences': bad_sequences_count,
            'total_issues': total_issues,
            'bad_sequence_ratio': bad_sequences_count / total_sequences if total_sequences > 0 else 0,
            'issue_type_stats': dict(issue_type_stats),
            'severity_stats': dict(severity_stats)
        },
        'thresholds': THRESHOLDS,
        'missing_sequences': missing_sequences,
        'sequence_details': all_results,
        'bad_sequences': bad_sequences
    }
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_path = os.path.join(OUTPUT_DIR, REPORT_FILE)
    with open(report_path, 'w') as f:
        json.dump(report_data, f, indent=2, default=str)
    
    # ç”Ÿæˆæ‘˜è¦æ–‡æœ¬
    summary_path = os.path.join(OUTPUT_DIR, SUMMARY_FILE)
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("NuPlan Poseè´¨é‡æ£€æŸ¥æŠ¥å‘Š (å®é™…ä½¿ç”¨çš„åºåˆ—)\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("ğŸ“Š æ€»ä½“ç»Ÿè®¡:\n")
        f.write(f"  å®é™…ä½¿ç”¨çš„åºåˆ—æ•°: {len(used_sequences):,}\n")
        f.write(f"  æˆåŠŸæ£€æŸ¥çš„åºåˆ—æ•°: {total_sequences:,}\n")
        f.write(f"  ç¼ºå¤±çš„åºåˆ—æ•°: {len(missing_sequences):,}\n")
        f.write(f"  æ­£å¸¸åºåˆ—æ•°: {good_sequences_count:,} ({good_sequences_count/total_sequences*100:.1f}%)\n")
        f.write(f"  é—®é¢˜åºåˆ—æ•°: {bad_sequences_count:,} ({bad_sequences_count/total_sequences*100:.1f}%)\n")
        f.write(f"  æ€»é—®é¢˜æ•°: {total_issues:,}\n\n")
        
        if missing_sequences:
            f.write("âŒ ç¼ºå¤±çš„åºåˆ—æ–‡ä»¶:\n")
            for seq in missing_sequences[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                f.write(f"  {seq}\n")
            if len(missing_sequences) > 10:
                f.write(f"  ... è¿˜æœ‰ {len(missing_sequences) - 10} ä¸ªç¼ºå¤±åºåˆ—\n")
            f.write("\n")
        
        f.write("ğŸ” é—®é¢˜ç±»å‹ç»Ÿè®¡:\n")
        for issue_type, count in sorted(issue_type_stats.items(), key=lambda x: x[1], reverse=True):
            f.write(f"  {issue_type}: {count:,}\n")
        f.write("\n")
        
        f.write("âš ï¸ ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡:\n")
        f.write(f"  ä¸¥é‡é—®é¢˜: {severity_stats['critical']:,}\n")
        f.write(f"  è­¦å‘Šé—®é¢˜: {severity_stats['warning']:,}\n\n")
        
        f.write("ğŸ¯ æ£€æŸ¥é˜ˆå€¼:\n")
        for key, value in THRESHOLDS.items():
            f.write(f"  {key}: {value}\n")
        f.write("\n")
        
        f.write("ğŸš¨ æœ€ä¸¥é‡çš„é—®é¢˜åºåˆ— (å‰10ä¸ª):\n")
        sorted_bad = sorted(bad_sequences.items(), key=lambda x: len(x[1]), reverse=True)
        for i, (seq_name, issues) in enumerate(sorted_bad[:10]):
            f.write(f"  {i+1}. {seq_name}: {len(issues)} ä¸ªé—®é¢˜\n")
        
        if bad_sequences:
            f.write("\nğŸ“ å…¸å‹é—®é¢˜ç¤ºä¾‹:\n")
            example_shown = set()
            for seq_name, issues in sorted_bad[:3]:
                for issue in issues[:2]:  # æ¯ä¸ªåºåˆ—æœ€å¤šæ˜¾ç¤º2ä¸ªé—®é¢˜
                    issue_type = issue['type']
                    if issue_type not in example_shown:
                        f.write(f"  {issue_type}: {issue.get('message', 'No message')}\n")
                        example_shown.add(issue_type)
    
    # ç”Ÿæˆå¯è§†åŒ–
    generate_visualizations(all_metrics, bad_sequences, OUTPUT_DIR)
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("ğŸ¯ æ£€æŸ¥å®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“Š å®é™…ä½¿ç”¨çš„åºåˆ—æ•°: {len(used_sequences):,}")
    print(f"ğŸ“Š æˆåŠŸæ£€æŸ¥çš„åºåˆ—æ•°: {total_sequences:,}")
    if missing_sequences:
        print(f"âŒ ç¼ºå¤±çš„åºåˆ—æ•°: {len(missing_sequences):,}")
    print(f"âœ… æ­£å¸¸åºåˆ—: {good_sequences_count:,} ({good_sequences_count/total_sequences*100:.1f}%)")
    print(f"âŒ é—®é¢˜åºåˆ—: {bad_sequences_count:,} ({bad_sequences_count/total_sequences*100:.1f}%)")
    print(f"ğŸš¨ æ€»é—®é¢˜æ•°: {total_issues:,}")
    
    if bad_sequences_count > 0:
        print(f"\nğŸ”¥ æœ€ä¸¥é‡çš„é—®é¢˜åºåˆ—:")
        sorted_bad = sorted(bad_sequences.items(), key=lambda x: len(x[1]), reverse=True)
        for i, (seq_name, issues) in enumerate(sorted_bad[:5]):
            print(f"  {i+1}. {seq_name}: {len(issues)} ä¸ªé—®é¢˜")
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
    print(f"  ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
    print(f"  ğŸ“ æ‘˜è¦æŠ¥å‘Š: {summary_path}")
    print(f"  ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {OUTPUT_DIR}/pose_quality_analysis.png")

if __name__ == "__main__":
    main() 